<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Project Update – Portfolio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./appendix-a-etl-rag.html" rel="next">
<link href="./references.html" rel="prev">
<link href="./pic/cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./update.html">Project Update</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Portfolio</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-proposal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Literature Analytics and Methodological Gap Analysis in Geospatial Epidemiology</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-data-collection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Collection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-literature-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Literature Review</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-prelim-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Preliminary Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-aim3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Proposed Deep Learning Framework for UOG Site Monitoring (Aim 3)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-technical-report.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Technical Report</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./update.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Project Update</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-a-etl-rag.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">appendix-a-etl-rag.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-b-lca-rf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Preliminary LCA Cover crop Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-c-hardware.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Appendix C: Computational Hardware</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-d-neo4j-queries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Knowledge Graph Queries and Supporting Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-e-db-queries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Database Queries</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#week-0" id="toc-week-0" class="nav-link active" data-scroll-target="#week-0">Week 0</a></li>
  <li><a href="#week-1" id="toc-week-1" class="nav-link" data-scroll-target="#week-1">Week 1</a></li>
  <li><a href="#week-2" id="toc-week-2" class="nav-link" data-scroll-target="#week-2">Week 2</a></li>
  <li><a href="#week-3" id="toc-week-3" class="nav-link" data-scroll-target="#week-3">Week 3</a></li>
  <li><a href="#week-4" id="toc-week-4" class="nav-link" data-scroll-target="#week-4">Week 4</a></li>
  <li><a href="#week-5-february-8---february-14" id="toc-week-5-february-8---february-14" class="nav-link" data-scroll-target="#week-5-february-8---february-14">Week 5 (February 8 - February 14)</a>
  <ul>
  <li><a href="#feb-8" id="toc-feb-8" class="nav-link" data-scroll-target="#feb-8">Feb 8</a></li>
  <li><a href="#feb-9" id="toc-feb-9" class="nav-link" data-scroll-target="#feb-9">Feb 9</a></li>
  <li><a href="#feb-10" id="toc-feb-10" class="nav-link" data-scroll-target="#feb-10">Feb 10</a></li>
  <li><a href="#feb-11" id="toc-feb-11" class="nav-link" data-scroll-target="#feb-11">Feb 11</a></li>
  <li><a href="#feb-12" id="toc-feb-12" class="nav-link" data-scroll-target="#feb-12">Feb 12</a></li>
  </ul></li>
  <li><a href="#week-6-february-15---february-21" id="toc-week-6-february-15---february-21" class="nav-link" data-scroll-target="#week-6-february-15---february-21">Week 6 (February 15 - February 21)</a>
  <ul>
  <li><a href="#feb-15" id="toc-feb-15" class="nav-link" data-scroll-target="#feb-15">Feb 15</a></li>
  <li><a href="#feb-16" id="toc-feb-16" class="nav-link" data-scroll-target="#feb-16">Feb 16</a></li>
  <li><a href="#feb-17" id="toc-feb-17" class="nav-link" data-scroll-target="#feb-17">Feb 17</a></li>
  <li><a href="#feb-18" id="toc-feb-18" class="nav-link" data-scroll-target="#feb-18">Feb 18</a></li>
  <li><a href="#feb-19" id="toc-feb-19" class="nav-link" data-scroll-target="#feb-19">Feb 19</a></li>
  <li><a href="#feb-20" id="toc-feb-20" class="nav-link" data-scroll-target="#feb-20">Feb 20</a></li>
  <li><a href="#feb-21" id="toc-feb-21" class="nav-link" data-scroll-target="#feb-21">Feb 21</a></li>
  </ul></li>
  <li><a href="#week-7-february-22---february-23" id="toc-week-7-february-22---february-23" class="nav-link" data-scroll-target="#week-7-february-22---february-23">Week 7 (February 22 - February 23)</a>
  <ul>
  <li><a href="#feb-22" id="toc-feb-22" class="nav-link" data-scroll-target="#feb-22">Feb 22</a></li>
  <li><a href="#feb-23" id="toc-feb-23" class="nav-link" data-scroll-target="#feb-23">Feb 23</a></li>
  <li><a href="#week-8-february-24---march-2-2025" id="toc-week-8-february-24---march-2-2025" class="nav-link" data-scroll-target="#week-8-february-24---march-2-2025">Week 8 (February 24 - March 2, 2025)</a></li>
  </ul></li>
  <li><a href="#weeks-9-12-march-3---march-30-2025" id="toc-weeks-9-12-march-3---march-30-2025" class="nav-link" data-scroll-target="#weeks-9-12-march-3---march-30-2025">Weeks 9-12 (March 3 - March 30, 2025)</a></li>
  <li><a href="#weeks-13-16-march-31---april-27-2025" id="toc-weeks-13-16-march-31---april-27-2025" class="nav-link" data-scroll-target="#weeks-13-16-march-31---april-27-2025">Weeks 13-16 (March 31 - April 27, 2025)</a></li>
  <li><a href="#weeks-17-18-april-28---may-11-2025" id="toc-weeks-17-18-april-28---may-11-2025" class="nav-link" data-scroll-target="#weeks-17-18-april-28---may-11-2025">Weeks 17-18 (April 28 - May 11, 2025)</a></li>
  <li><a href="#week-19-may-12---may-18-2025" id="toc-week-19-may-12---may-18-2025" class="nav-link" data-scroll-target="#week-19-may-12---may-18-2025">Week 19 (May 12 - May 18, 2025)</a></li>
  <li><a href="#week-20-may-19---may-22-2025" id="toc-week-20-may-19---may-22-2025" class="nav-link" data-scroll-target="#week-20-may-19---may-22-2025">Week 20 (May 19 - May 22, 2025)</a></li>
  <li><a href="#week-21-may-23---may-29-2025" id="toc-week-21-may-23---may-29-2025" class="nav-link" data-scroll-target="#week-21-may-23---may-29-2025">Week 21 (May 23 - May 29, 2025)</a></li>
  <li><a href="#week-22-may-30---june-7-2025" id="toc-week-22-may-30---june-7-2025" class="nav-link" data-scroll-target="#week-22-may-30---june-7-2025">Week 22 (May 30 - June 7, 2025)</a></li>
  <li><a href="#week-23-june-8---present-ongoing" id="toc-week-23-june-8---present-ongoing" class="nav-link" data-scroll-target="#week-23-june-8---present-ongoing">Week 23 (June 8 - Present, Ongoing)</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Project Update</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>For updates on the ETL and RAG project, please visit my <strong>Github:</strong> page: <a href="https://github.com/agodinezmm2007">github.com/agodinezmm2007</a></p>
<p>Please note that the RAG repository is private, please contact for access.</p>
<section id="week-0" class="level2">
<h2 class="anchored" data-anchor-id="week-0">Week 0</h2>
<ul>
<li>Started preliminary work on literature. Taking a lot of time, need to find faster solution.</li>
</ul>
</section>
<section id="week-1" class="level2">
<h2 class="anchored" data-anchor-id="week-1">Week 1</h2>
<ul>
<li>Read about retrieval augmented generation (RAG). This approach may drastically improve the literature-search step by embedding references and using an LLM to retrieve relevant passages.</li>
</ul>
</section>
<section id="week-2" class="level2">
<h2 class="anchored" data-anchor-id="week-2">Week 2</h2>
<ul>
<li>Spent significant time building an ETL pipeline: installed conda and FAISS for vector indexing.<br>
</li>
<li>Realized PDF text extraction would be critical, tried PyPDF2 but it wasn’t good at extracting tables.</li>
<li>Started exploring Azure Document Intelligence as an alternative.</li>
</ul>
</section>
<section id="week-3" class="level2">
<h2 class="anchored" data-anchor-id="week-3">Week 3</h2>
<ul>
<li>Successfully tested Azure Document Intelligence. It can parse text and tables with higher accuracy than PyPDF2.<br>
</li>
<li>Began integrated script to pipeline: <code>get_pdf_from_unpaywall()</code>, <code>AzurePDFExtractor()</code>.</li>
</ul>
</section>
<section id="week-4" class="level2">
<h2 class="anchored" data-anchor-id="week-4">Week 4</h2>
<ul>
<li>Downloaded and extracted text from ~947 PDFs. Stored full text and tables in <code>.feather</code> format.</li>
<li>Attempted a first pass at data extraction <em>after</em> chunking/embedding, which caused the LLM to shuffle fields incorrectly (in-text citation ended up in the “Title” field).</li>
<li>Reversed approach: performed data extraction <strong>before</strong> chunking. This fixed the mismatch issue. Confirmed with a sample of 20 PDFs.</li>
<li>Chain-of-thought (CoT) pipeline flagged repeated metadata assignment errors—a sign that the agentic QA steps are working.</li>
</ul>
<hr>
</section>
<section id="week-5-february-8---february-14" class="level2">
<h2 class="anchored" data-anchor-id="week-5-february-8---february-14">Week 5 (February 8 - February 14)</h2>
<section id="feb-8" class="level3">
<h3 class="anchored" data-anchor-id="feb-8">Feb 8</h3>
<ul>
<li><strong>Goal</strong>: Integrate LDA-based topic modeling to see if we can auto-categorize large numbers of articles before the RAG step.<br>
</li>
<li>Installed <code>gensim</code> for LDA experiments. Began experimenting with short pilot on 100 articles to cluster them by topic.</li>
</ul>
</section>
<section id="feb-9" class="level3">
<h3 class="anchored" data-anchor-id="feb-9">Feb 9</h3>
<ul>
<li><strong>Pipeline Enhancement</strong>:
<ul>
<li>Added a <strong>“topic modeling”</strong> function that runs after text extraction but before chunking. Currently operational.<br>
</li>
<li>Verified that the topic assignment is stored in a new column (e.g., <code>TopicLabel</code>) for each article.<br>
</li>
</ul></li>
<li>Performed initial tests on ~20 PDFs. Topics looked coherent, but some short abstracts were mislabeled.</li>
</ul>
</section>
<section id="feb-10" class="level3">
<h3 class="anchored" data-anchor-id="feb-10">Feb 10</h3>
<ul>
<li><strong>RAG Implementation</strong>:
<ul>
<li>Integrated the new topic labels into the retrieval step. If user query references a domain (e.g.&nbsp;“epidemiology” or “machine learning”), we can first filter for relevant topics.<br>
</li>
<li>Retried the “Impacts of cover crops on carbon sequestration?” query. The chain-of-thought reasoning is more direct now that we skip non-relevant topics.</li>
</ul></li>
</ul>
</section>
<section id="feb-11" class="level3">
<h3 class="anchored" data-anchor-id="feb-11">Feb 11</h3>
<ul>
<li><strong>Agentic QA Testing</strong>:
<ul>
<li>Posed domain-specific questions, like “What is the best method for measuring greenhouse gas flux in cover crops?” The RAG system returned multiple references with almost no hallucination.<br>
</li>
<li>Also tested random or unrelated queries, like “Ferrari vs.&nbsp;Lamborghini top speed” or “Socioeconomic status of transgender clowns in rural Siberia.” System returned a “lack of relevant info” answer—demonstrating good out-of-scope handling.</li>
</ul></li>
</ul>
</section>
<section id="feb-12" class="level3">
<h3 class="anchored" data-anchor-id="feb-12">Feb 12</h3>
<ul>
<li><strong>Debugging</strong>:
<ul>
<li>Found an edge case where the LLM would try to fabricate DOIs if there was no matching record. Added an explicit check so it returns “no data found.”, also made it invalidate the result if it cannot identify and retrieve four piece of metadata for the referenced articled in the generated response (DOI, in text citation, full citation, zoterokey). works perfectly</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="week-6-february-15---february-21" class="level2">
<h2 class="anchored" data-anchor-id="week-6-february-15---february-21">Week 6 (February 15 - February 21)</h2>
<section id="feb-15" class="level3">
<h3 class="anchored" data-anchor-id="feb-15">Feb 15</h3>
<ul>
<li><strong>Local LLM Setup</strong>:
<ul>
<li>Experimented with <code>Qwen-7B</code> and <code>LLama2-13B</code> locally for chunk embedding to reduce OpenAI API costs.<br>
</li>
<li>Performance is slower than OpenAI embeddings, but cost is zero. Considering a hybrid approach.</li>
</ul></li>
</ul>
</section>
<section id="feb-16" class="level3">
<h3 class="anchored" data-anchor-id="feb-16">Feb 16</h3>
<ul>
<li><strong>Chain-of-Thought Refinement</strong>:
<ul>
<li>Enhanced prompt to explicitly mention “If you cannot find a reference in the dataset, do not cite it.” This further reduced spurious citations.<br>
</li>
<li>Tweaked agentic evaluator to trigger <code>REGENERATE:</code> if any piece of required metadata (ZoteroKey, etc.) is missing.</li>
</ul></li>
</ul>
</section>
<section id="feb-17" class="level3">
<h3 class="anchored" data-anchor-id="feb-17">Feb 17</h3>
<ul>
<li><strong>Large-Scale Test</strong>:
<ul>
<li>Ran pipeline on ~947 articles. Performance was stable, but Azure Document Intelligence costs soared.<br>
</li>
<li>Decided to investigate open-source PDF extraction (Docling or Tesseract-based) as a fallback for basic text extraction.</li>
</ul></li>
</ul>
</section>
<section id="feb-18" class="level3">
<h3 class="anchored" data-anchor-id="feb-18">Feb 18</h3>
<ul>
<li><strong>Citation Management</strong>:
<ul>
<li>Verified that the <code>add_pdf_to_zotero()</code> function actually attaches each PDF and auto-generates an item with correct metadata.<br>
</li>
<li>Confirmed the <code>get_citation_csl_json()</code> yields accurate APA citations.</li>
</ul></li>
</ul>
</section>
<section id="feb-19" class="level3">
<h3 class="anchored" data-anchor-id="feb-19">Feb 19</h3>
<ul>
<li><strong>Topic Modeling Revisited</strong>:
<ul>
<li>Need to create a separate <code>.qmd</code> describing how i tested LDA to identify top 10 emergent topics.<br>
</li>
<li>will be writing up results in <code>02-data-collection.qmd</code>.</li>
<li>this is what will be used to identify research gaps and research topcis</li>
</ul></li>
</ul>
</section>
<section id="feb-20" class="level3">
<h3 class="anchored" data-anchor-id="feb-20">Feb 20</h3>
<ul>
<li><strong>RAG Pipeline Finalization</strong>:
<ul>
<li>Performed final checks on chunking logic (overlap=200 tokens).<br>
</li>
<li>Implemented a default “max_tokens=1000” for chunking. Verified no large chunk errors in Qdrant.</li>
</ul></li>
</ul>
</section>
<section id="feb-21" class="level3">
<h3 class="anchored" data-anchor-id="feb-21">Feb 21</h3>
<ul>
<li><strong>Validation</strong>:
<ul>
<li>Queried random nonsense (“Does this set of PDFs mention UFO sightings?”). RAG responded “No relevant data found,” consistent with actual dataset content.<br>
</li>
<li>Added logs to highlight any user query that yields zero results</li>
<li>Current system readiness: <strong>ETL &amp; RAG</strong> are stable, partial local inference available. Live demo possible</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="week-7-february-22---february-23" class="level2">
<h2 class="anchored" data-anchor-id="week-7-february-22---february-23">Week 7 (February 22 - February 23)</h2>
<section id="feb-22" class="level3">
<h3 class="anchored" data-anchor-id="feb-22">Feb 22</h3>
<ul>
<li><strong>Final Testing</strong>:
<ul>
<li>Conducted detailed test with domain questions (cover crops, greenhouse gas, climate change, etc.)</li>
<li>Observed zero hallucinations, only direct references to text in the chunk embeddings.</li>
</ul></li>
</ul>
</section>
<section id="feb-23" class="level3">
<h3 class="anchored" data-anchor-id="feb-23">Feb 23</h3>
<ul>
<li><strong>Conclusion</strong>:
<ul>
<li><strong>All major pipeline components</strong> (ETL + RAG + topic modeling) are operational.<br>
</li>
<li>Next steps: start looking for research gaps related to big data and geospatial analysis, sub-focus on environmental health or public health</li>
</ul></li>
</ul>
<hr>
</section>
<section id="week-8-february-24---march-2-2025" class="level3">
<h3 class="anchored" data-anchor-id="week-8-february-24---march-2-2025">Week 8 (February 24 - March 2, 2025)</h3>
<p><strong>Pipeline Integration Planning:</strong></p>
<ul>
<li>Began detailed planning for integrating the standalone ETL, topic modeling, and RAG modules into a cohesive, sequential automated pipeline.</li>
</ul>
<p><strong>GUI Scoping:</strong></p>
<ul>
<li>Outlined core requirements and desired functionalities for a PyQt-based Graphical User Interface (GUI) to manage pipeline configurations, execution, and monitoring.</li>
</ul>
<p><strong>Local LLM Strategy:</strong></p>
<ul>
<li>Finalized strategy to prioritize local LLM deployment (Qwen series) for core reasoning tasks to ensure cost-effectiveness and control, reserving API calls for specialized needs or fallback. ___</li>
</ul>
</section>
</section>
<section id="weeks-9-12-march-3---march-30-2025" class="level2">
<h2 class="anchored" data-anchor-id="weeks-9-12-march-3---march-30-2025">Weeks 9-12 (March 3 - March 30, 2025)</h2>
<p><strong>Sequential Pipeline Development:</strong></p>
<ul>
<li>Focused on scripting the end-to-end workflow, ensuring smooth data handoffs between modules: PDF acquisition (async_unpaywall.py), text/table extraction (docling_extract_formulas_mp_multi.py), metadata enrichment (field_extraction.py), Zotero integration (fast_zotero.py), topic modeling (topic_modeling_culda.py), knowledge graph population (kg_pipeline.py), and RAG querying (agentic_pipeline.py).</li>
</ul>
<p><strong>GUI Prototyping:</strong></p>
<ul>
<li>Developed initial versions of key GUI tabs using PyQt, including the configuration tab (config_tab.py) for managing etl_config.json and kg_pipeline.json, and basic pipeline control elements.</li>
</ul>
<p><strong>Local LLM Deployment (Qwen-QwQ32B):</strong></p>
<ul>
<li>Successfully deployed and began testing the Qwen/QwQ32B model locally. Started adapting the agentic_pipeline.py to utilize this model for its advanced reasoning and instruction-following capabilities, noting improved output quality over smaller local models. ___</li>
</ul>
</section>
<section id="weeks-13-16-march-31---april-27-2025" class="level2">
<h2 class="anchored" data-anchor-id="weeks-13-16-march-31---april-27-2025">Weeks 13-16 (March 31 - April 27, 2025)</h2>
<p><strong>GUI Enhancement &amp; Integration:</strong></p>
<ul>
<li>Significantly advanced GUI development, enabling full pipeline orchestration from the interface. Implemented features for selecting specific fields for LLM extraction, initiating pipeline runs, and monitoring progress.</li>
</ul>
<p><strong>Qwen3-32B Integration &amp; Agentic Pipeline Refinement:</strong></p>
<p>Replaced Qwen/QwQ32 model with Qwen3-32B. the reason is because the QwQ model thinks too hard. Integrated Qwen3-32B into the field_extraction.py and agentic_pipeline.py for all core LLM tasks (field extraction, CoT reasoning, agentic evaluation, QA checks). Conducted extensive testing, confirming superior instruction adherence and output quality compared to previous models, albeit with increased generation time. Developed robust error handling for local LLM inference.</p>
<p><strong>Fine-tuning Data Logging:</strong></p>
<ul>
<li>Implemented systematic logging of curated LLM interactions (prompts, agentic feedback, final outputs) from the agentic_pipeline.py into a structured JSON format, creating a valuable dataset for potential future fine-tuning of domain-specific LLMs.</li>
</ul>
<hr>
</section>
<section id="weeks-17-18-april-28---may-11-2025" class="level2">
<h2 class="anchored" data-anchor-id="weeks-17-18-april-28---may-11-2025">Weeks 17-18 (April 28 - May 11, 2025)</h2>
<p><strong>Milestone - Fully Integrated System Operational</strong></p>
<ul>
<li>Achieved full operational status for the sequential ETL+RAG pipeline, orchestrated via the GUI and utilizing the locally deployed Qwen3-32B LLM.</li>
</ul>
<p><strong>Ozone-CVD Literature Review Application:</strong></p>
<ul>
<li>Commenced the systematic application of the finalized pipeline to the target literature corpus on ozone exposure, cardiovascular disease, and analytical methodologies, as outlined for the 03-literature-review.qmd. This involved automated data extraction, knowledge graph population, and RAG-based synthesis to identify methodological gaps.</li>
</ul>
<p><strong>LCA/GWP System Demonstration:</strong></p>
<ul>
<li>Conducted a focused application of the pipeline to a selection of literature on Life Cycle Assessment (LCA) and Global Warming Potential (GWP) in agricultural systems. This successfully demonstrates the system’s interdisciplinary adaptability, particularly its ability to extract LCI data using the configurable field_extraction.py and specialized dictionaries. ___</li>
</ul>
</section>
<section id="week-19-may-12---may-18-2025" class="level2">
<h2 class="anchored" data-anchor-id="week-19-may-12---may-18-2025">Week 19 (May 12 - May 18, 2025)</h2>
<p><strong>Literature Review Finalization:</strong></p>
<ul>
<li>Completed the primary data extraction, analysis, and synthesis phases for the ozone-CVD literature review (03-literature-review.qmd) using the pipeline’s outputs. This included finalizing the PRISMA-guided study selection facilitated by knowledge graph queries.</li>
</ul>
<p><strong>Ozone-CVD Empirical Analysis - Data Preparation:</strong></p>
<ul>
<li>Initiated data preprocessing for the CDC ozone and CVD mortality datasets, as detailed in notebooks/data_preparation.ipynb. This involved cleaning, merging, and feature engineering to prepare the data for modeling.</li>
</ul>
<p><strong>Preliminary Model Development (Random Forest):</strong> Began development and initial training runs of the Random Forest model for the preliminary ozone-CVD analysis, detailed in notebooks/random_forest.ipynb and discussed in 04-analysis.qmd. ___</p>
</section>
<section id="week-20-may-19---may-22-2025" class="level2">
<h2 class="anchored" data-anchor-id="week-20-may-19---may-22-2025">Week 20 (May 19 - May 22, 2025)</h2>
<p><strong>Project Documentation &amp; Reporting:</strong></p>
<ul>
<li>Focused on documenting the project’s progress, including finalizing this “Project Update” section and drafting other components of the overall project report/proposal.</li>
</ul>
<p><strong>Preliminary Analysis Interpretation:</strong></p>
<ul>
<li>Continued in-depth analysis and interpretation of the results from the preliminary Random Forest model for ozone-CVD associations, including SHAP value analysis.</li>
</ul>
<p><strong>Advanced Modeling Strategy Refinement:</strong></p>
<p>Further refined the analytical plan for applying CNNs and GNNs to the ozone-CVD data, incorporating insights from the literature review and the preliminary Random Forest findings.</p>
<p><strong>Current System Readiness:</strong></p>
<ul>
<li>The AI-Powered ETL &amp; RAG system is fully operational, GUI-driven, and leverages a high-quality local LLM. It has been successfully applied to generate a comprehensive literature review and is supporting ongoing empirical data analysis. ___</li>
</ul>
</section>
<section id="week-21-may-23---may-29-2025" class="level2">
<h2 class="anchored" data-anchor-id="week-21-may-23---may-29-2025">Week 21 (May 23 - May 29, 2025)</h2>
<p><strong>Preliminary Analysis Completion (Aim 2):</strong></p>
<ul>
<li>Completed the full analytical pipeline for the preliminary Random Forest model, predicting ozone-CVD mortality rates.</li>
<li>Finalized the data preprocessing steps, including the log-transformation of the outcome variable and key covariates.</li>
<li>Executed the hyperparameter tuning (<code>RandomizedSearchCV</code>) and generated all model evaluation metrics (R², RMSE, MAE, OOB score).</li>
<li>Produced and interpreted all model explanation outputs, including permutation feature importance and a full suite of global and local SHAP analyses.</li>
<li>Authored the complete <code>04-prelim-analysis.qmd</code> chapter, documenting the methodology and presenting the findings.</li>
</ul>
<hr>
</section>
<section id="week-22-may-30---june-7-2025" class="level2">
<h2 class="anchored" data-anchor-id="week-22-may-30---june-7-2025">Week 22 (May 30 - June 7, 2025)</h2>
<p><strong>Technical Documentation (Aim 1):</strong></p>
<ul>
<li>Shifted focus from analysis to comprehensive documentation of the core research instrument.</li>
<li>Drafted and completed the full <code>05-technical-report.qmd</code> chapter, detailing the architecture and theory of operation for the entire ETL+RAG system.</li>
<li>Documented the extensive re-engineering of the <code>Docling</code> library, including the custom parallelization architecture, the “SmolDocling” model integration, and the advanced post-processing heuristics.</li>
<li>Created and published the public <code>docling_mod</code> GitHub repository, packaging the modified codebase, testing scripts, and sample data to ensure transparency and reproducibility.</li>
</ul>
</section>
<section id="week-23-june-8---present-ongoing" class="level2">
<h2 class="anchored" data-anchor-id="week-23-june-8---present-ongoing">Week 23 (June 8 - Present, Ongoing)</h2>
<p><strong>Advanced Methodology Conceptualization (Aim 3):</strong></p>
<ul>
<li>Began conceptualizing and structuring the final research aim: the deep learning framework for UOG site monitoring.</li>
<li>Outlined the two-phase approach, starting with CNN-based object detection for site identification and followed by spatiotemporal (ConvLSTM) analysis of methane data.</li>
<li>Developed the novel methodological proposal to use county tax parcel data as a masking layer to improve computational efficiency and model performance.</li>
<li>Drafted a new dissertation chapter dedicated to this proposed methodology, including a detailed, realistic project timeline and key milestones.</li>
</ul>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./references.html" class="pagination-link" aria-label="References">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">References</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./appendix-a-etl-rag.html" class="pagination-link" aria-label="appendix-a-etl-rag.html">
        <span class="nav-page-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">appendix-a-etl-rag.html</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Project Update {.unnumbered}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>For updates on the ETL and RAG project, please visit my **Github:** page: <span class="co">[</span><span class="ot">github.com/agodinezmm2007</span><span class="co">](https://github.com/agodinezmm2007)</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>Please note that the RAG repository is private, please contact for access.</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 0</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Started preliminary work on literature. Taking a lot of time, need to find faster solution.</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 1</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Read about retrieval augmented generation (RAG). This approach may drastically improve the literature-search step by embedding references and using an LLM to retrieve relevant passages.</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 2</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Spent significant time building an ETL pipeline: installed conda and FAISS for vector indexing.  </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Realized PDF text extraction would be critical, tried PyPDF2 but it wasn’t good at extracting tables.</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Started exploring Azure Document Intelligence as an alternative.</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 3</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Successfully tested Azure Document Intelligence. It can parse text and tables with higher accuracy than PyPDF2.  </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Began integrated script to pipeline: <span class="in">`get_pdf_from_unpaywall()`</span>, <span class="in">`AzurePDFExtractor()`</span>.</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 4</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Downloaded and extracted text from ~947 PDFs. Stored full text and tables in <span class="in">`.feather`</span> format.</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Attempted a first pass at data extraction *after* chunking/embedding, which caused the LLM to shuffle fields incorrectly (in-text citation ended up in the “Title” field).</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Reversed approach: performed data extraction **before** chunking. This fixed the mismatch issue. Confirmed with a sample of 20 PDFs.</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Chain-of-thought (CoT) pipeline flagged repeated metadata assignment errors—a sign that the agentic QA steps are working.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 5 (February 8 - February 14)</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 8</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Goal**: Integrate LDA-based topic modeling to see if we can auto-categorize large numbers of articles before the RAG step.  </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Installed <span class="in">`gensim`</span> for LDA experiments. Began experimenting with short pilot on 100 articles to cluster them by topic.  </span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 9</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Pipeline Enhancement**:  </span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Added a **“topic modeling”** function that runs after text extraction but before chunking. Currently operational.  </span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Verified that the topic assignment is stored in a new column (e.g., <span class="in">`TopicLabel`</span>) for each article.  </span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Performed initial tests on ~20 PDFs. Topics looked coherent, but some short abstracts were mislabeled.</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 10</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**RAG Implementation**:  </span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Integrated the new topic labels into the retrieval step. If user query references a domain (e.g. “epidemiology” or “machine learning”), we can first filter for relevant topics.  </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Retried the “Impacts of cover crops on carbon sequestration?” query. The chain-of-thought reasoning is more direct now that we skip non-relevant topics.  </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 11</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Agentic QA Testing**:  </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Posed domain-specific questions, like “What is the best method for measuring greenhouse gas flux in cover crops?” The RAG system returned multiple references with almost no hallucination.  </span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Also tested random or unrelated queries, like “Ferrari vs. Lamborghini top speed” or “Socioeconomic status of transgender clowns in rural Siberia.” System returned a “lack of relevant info” answer—demonstrating good out-of-scope handling.  </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 12</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Debugging**:  </span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Found an edge case where the LLM would try to fabricate DOIs if there was no matching record. Added an explicit check so it returns “no data found.”, also made it invalidate the result if</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>  it cannot identify and retrieve four piece of metadata for the referenced articled in the generated response (DOI, in text citation, full citation, zoterokey). works perfectly  </span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 6 (February 15 - February 21)</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 15</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Local LLM Setup**:  </span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Experimented with <span class="in">`Qwen-7B`</span> and <span class="in">`LLama2-13B`</span> locally for chunk embedding to reduce OpenAI API costs.  </span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Performance is slower than OpenAI embeddings, but cost is zero. Considering a hybrid approach.</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 16</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Chain-of-Thought Refinement**:  </span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Enhanced prompt to explicitly mention “If you cannot find a reference in the dataset, do not cite it.” This further reduced spurious citations.  </span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Tweaked agentic evaluator to trigger <span class="in">`REGENERATE:`</span> if any piece of required metadata (ZoteroKey, etc.) is missing.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 17</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Large-Scale Test**:  </span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Ran pipeline on ~947 articles. Performance was stable, but Azure Document Intelligence costs soared.  </span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Decided to investigate open-source PDF extraction (Docling or Tesseract-based) as a fallback for basic text extraction.</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 18</span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Citation Management**:  </span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Verified that the <span class="in">`add_pdf_to_zotero()`</span> function actually attaches each PDF and auto-generates an item with correct metadata.  </span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Confirmed the <span class="in">`get_citation_csl_json()`</span> yields accurate APA citations.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 19</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Topic Modeling Revisited**:  </span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Need to create a separate <span class="in">`.qmd`</span> describing how i tested LDA to identify top 10 emergent topics.  </span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>will be writing up results in <span class="in">`02-data-collection.qmd`</span>.</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>this is what will be used to identify research gaps and research topcis</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 20</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**RAG Pipeline Finalization**:  </span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Performed final checks on chunking logic (overlap=200 tokens).  </span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Implemented a default “max_tokens=1000” for chunking. Verified no large chunk errors in Qdrant.</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 21</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Validation**:  </span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Queried random nonsense (“Does this set of PDFs mention UFO sightings?”). RAG responded “No relevant data found,” consistent with actual dataset content.  </span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Added logs to highlight any user query that yields zero results</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Current system readiness: **ETL &amp; RAG** are stable, partial local inference available. Live demo possible</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 7 (February 22 - February 23)</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 22</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Final Testing**:  </span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Conducted detailed test with domain questions (cover crops, greenhouse gas, climate change, etc.)</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Observed zero hallucinations, only direct references to text in the chunk embeddings.</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feb 23</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Conclusion**:  </span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**All major pipeline components** (ETL + RAG + topic modeling) are operational.  </span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Next steps: start looking for research gaps related to big data and geospatial analysis, sub-focus on environmental health or public health</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="fu">### Week 8 (February 24 - March 2, 2025)</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>**Pipeline Integration Planning:**</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Began detailed planning for integrating the standalone ETL, topic modeling, and RAG modules into a cohesive, sequential automated pipeline.</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>**GUI Scoping:**</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Outlined core requirements and desired functionalities for a PyQt-based Graphical User Interface (GUI) to manage pipeline configurations, execution, and monitoring.</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>**Local LLM Strategy:**</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Finalized strategy to prioritize local LLM deployment (Qwen series) for core reasoning tasks to ensure cost-effectiveness and control, reserving API calls for specialized needs or fallback.</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="fu">## Weeks 9-12 (March 3 - March 30, 2025)</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>**Sequential Pipeline Development:** </span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Focused on scripting the end-to-end workflow, ensuring smooth data handoffs between modules: PDF acquisition (async_unpaywall.py), text/table extraction (docling_extract_formulas_mp_multi.py), metadata enrichment (field_extraction.py), Zotero integration (fast_zotero.py), topic modeling (topic_modeling_culda.py), knowledge graph population (kg_pipeline.py), and RAG querying (agentic_pipeline.py).</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>**GUI Prototyping:**</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Developed initial versions of key GUI tabs using PyQt, including the configuration tab (config_tab.py) for managing etl_config.json and kg_pipeline.json, and basic pipeline control elements.</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>**Local LLM Deployment (Qwen-QwQ32B):**</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Successfully deployed and began testing the Qwen/QwQ32B model locally. Started adapting the agentic_pipeline.py to utilize this model for its advanced reasoning and instruction-following capabilities, noting improved output quality over smaller local models.</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a><span class="fu">## Weeks 13-16 (March 31 - April 27, 2025)</span></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>**GUI Enhancement &amp; Integration:** </span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Significantly advanced GUI development, enabling full pipeline orchestration from the interface. Implemented features for selecting specific fields for LLM extraction, initiating pipeline runs, and monitoring progress.</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>**Qwen3-32B Integration &amp; Agentic Pipeline Refinement:**</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>Replaced Qwen/QwQ32 model with Qwen3-32B. the reason is because the QwQ model thinks too hard. Integrated Qwen3-32B into the field_extraction.py and agentic_pipeline.py for all core LLM tasks (field extraction, CoT reasoning, agentic evaluation, QA checks). Conducted extensive testing, confirming superior instruction adherence and output quality compared to previous models, albeit with increased generation time. Developed robust error handling for local LLM inference.</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>**Fine-tuning Data Logging:** </span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Implemented systematic logging of curated LLM interactions (prompts, agentic feedback, final outputs) from the agentic_pipeline.py into a structured JSON format, creating a valuable dataset for potential future fine-tuning of domain-specific LLMs.</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="fu">## Weeks 17-18 (April 28 - May 11, 2025)</span></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>**Milestone - Fully Integrated System Operational**</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Achieved full operational status for the sequential ETL+RAG pipeline, orchestrated via the GUI and utilizing the locally deployed Qwen3-32B LLM.</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>**Ozone-CVD Literature Review Application:**</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Commenced the systematic application of the finalized pipeline to the target literature corpus on ozone exposure, cardiovascular disease, and analytical methodologies, as outlined for the 03-literature-review.qmd. This involved automated data extraction, knowledge graph population, and RAG-based synthesis to identify methodological gaps.</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>**LCA/GWP System Demonstration:**</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Conducted a focused application of the pipeline to a selection of literature on Life Cycle Assessment (LCA) and Global Warming Potential (GWP) in agricultural systems. This successfully demonstrates the system's interdisciplinary adaptability, particularly its ability to extract LCI data using the configurable field_extraction.py and specialized dictionaries.</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 19 (May 12 - May 18, 2025)</span></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>**Literature Review Finalization:**</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Completed the primary data extraction, analysis, and synthesis phases for the ozone-CVD literature review (03-literature-review.qmd) using the pipeline's outputs. This included finalizing the PRISMA-guided study selection facilitated by knowledge graph queries.</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>**Ozone-CVD Empirical Analysis - Data Preparation:** </span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Initiated data preprocessing for the CDC ozone and CVD mortality datasets, as detailed in notebooks/data_preparation.ipynb. This involved cleaning, merging, and feature engineering to prepare the data for modeling.</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>**Preliminary Model Development (Random Forest):**</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>Began development and initial training runs of the Random Forest model for the preliminary ozone-CVD analysis, detailed in notebooks/random_forest.ipynb and discussed in 04-analysis.qmd.</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 20 (May 19 - May 22, 2025)</span></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>**Project Documentation &amp; Reporting:** </span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Focused on documenting the project's progress, including finalizing this "Project Update" section and drafting other components of the overall project report/proposal.</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>**Preliminary Analysis Interpretation:** </span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Continued in-depth analysis and interpretation of the results from the preliminary Random Forest model for ozone-CVD associations, including SHAP value analysis.</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>**Advanced Modeling Strategy Refinement:** </span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>Further refined the analytical plan for applying CNNs and GNNs to the ozone-CVD data, incorporating insights from the literature review and the preliminary Random Forest findings.</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>**Current System Readiness:**</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The AI-Powered ETL &amp; RAG system is fully operational, GUI-driven, and leverages a high-quality local LLM. It has been successfully applied to generate a comprehensive literature review and is supporting ongoing empirical data analysis.</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 21 (May 23 - May 29, 2025)</span></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>**Preliminary Analysis Completion (Aim 2):**</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Completed the full analytical pipeline for the preliminary Random Forest model, predicting ozone-CVD mortality rates. </span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Finalized the data preprocessing steps, including the log-transformation of the outcome variable and key covariates. </span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Executed the hyperparameter tuning (<span class="in">`RandomizedSearchCV`</span>) and generated all model evaluation metrics (R², RMSE, MAE, OOB score). </span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Produced and interpreted all model explanation outputs, including permutation feature importance and a full suite of global and local SHAP analyses. </span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Authored the complete <span class="in">`04-prelim-analysis.qmd`</span> chapter, documenting the methodology and presenting the findings. </span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>___</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 22 (May 30 - June 7, 2025)</span></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>**Technical Documentation (Aim 1):**</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Shifted focus from analysis to comprehensive documentation of the core research instrument. </span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Drafted and completed the full <span class="in">`05-technical-report.qmd`</span> chapter, detailing the architecture and theory of operation for the entire ETL+RAG system. </span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Documented the extensive re-engineering of the <span class="in">`Docling`</span> library, including the custom parallelization architecture, the "SmolDocling" model integration, and the advanced post-processing heuristics. </span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Created and published the public <span class="in">`docling_mod`</span> GitHub repository, packaging the modified codebase, testing scripts, and sample data to ensure transparency and reproducibility. </span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a><span class="fu">## Week 23 (June 8 - Present, Ongoing)</span></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>**Advanced Methodology Conceptualization (Aim 3):**</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Began conceptualizing and structuring the final research aim: the deep learning framework for UOG site monitoring. </span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Outlined the two-phase approach, starting with CNN-based object detection for site identification and followed by spatiotemporal (ConvLSTM) analysis of methane data. </span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Developed the novel methodological proposal to use county tax parcel data as a masking layer to improve computational efficiency and model performance. </span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Drafted a new dissertation chapter dedicated to this proposed methodology, including a detailed, realistic project timeline and key milestones. </span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Written by Alex Godinez | <a href="https://github.com/agodinezmm2007">GitHub</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>