<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alex Godinez">
<meta name="dcterms.date" content="2025-06-13">

<title>2&nbsp; Literature Analytics and Methodological Gap Analysis in Geospatial Epidemiology – Portfolio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./02-data-collection.html" rel="next">
<link href="./intro.html" rel="prev">
<link href="./pic/cover.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-proposal.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Literature Analytics and Methodological Gap Analysis in Geospatial Epidemiology</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Portfolio</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-proposal.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Literature Analytics and Methodological Gap Analysis in Geospatial Epidemiology</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-data-collection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Collection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-literature-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Literature Review</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-prelim-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Preliminary Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-aim3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Proposed Deep Learning Framework for UOG Site Monitoring (Aim 3)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-technical-report.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Technical Report</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./update.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Update</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-a-etl-rag.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">appendix-a-etl-rag.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-b-lca-rf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Preliminary LCA Cover crop Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-c-hardware.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Appendix C: Computational Hardware</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-d-neo4j-queries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Knowledge Graph Queries and Supporting Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix-e-db-queries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Database Queries</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overall-goal" id="toc-overall-goal" class="nav-link active" data-scroll-target="#overall-goal"><span class="header-section-number">3</span> Overall Goal</a></li>
  <li><a href="#specific-aims-and-research-questions" id="toc-specific-aims-and-research-questions" class="nav-link" data-scroll-target="#specific-aims-and-research-questions"><span class="header-section-number">4</span> Specific Aims and Research Questions</a></li>
  <li><a href="#proposed-methodology-for-aim-3" id="toc-proposed-methodology-for-aim-3" class="nav-link" data-scroll-target="#proposed-methodology-for-aim-3"><span class="header-section-number">5</span> Proposed Methodology for Aim 3</a></li>
  <li><a href="#application-scenario" id="toc-application-scenario" class="nav-link" data-scroll-target="#application-scenario"><span class="header-section-number">6</span> Application Scenario</a></li>
  <li><a href="#personal-motivation-investment" id="toc-personal-motivation-investment" class="nav-link" data-scroll-target="#personal-motivation-investment"><span class="header-section-number">7</span> Personal Motivation &amp; Investment</a></li>
  <li><a href="#why-its-interesting" id="toc-why-its-interesting" class="nav-link" data-scroll-target="#why-its-interesting"><span class="header-section-number">8</span> Why It’s Interesting</a></li>
  <li><a href="#timeline" id="toc-timeline" class="nav-link" data-scroll-target="#timeline"><span class="header-section-number">9</span> Timeline</a></li>
  <li><a href="#interdisciplinary-collaboration-and-cross-domain-utility" id="toc-interdisciplinary-collaboration-and-cross-domain-utility" class="nav-link" data-scroll-target="#interdisciplinary-collaboration-and-cross-domain-utility"><span class="header-section-number">10</span> Interdisciplinary Collaboration and Cross-Domain Utility</a>
  <ul>
  <li><a href="#interdisciplinary-impact-example" id="toc-interdisciplinary-impact-example" class="nav-link" data-scroll-target="#interdisciplinary-impact-example"><span class="header-section-number">10.1</span> Interdisciplinary Impact Example</a></li>
  </ul></li>
  <li><a href="#societal-impact-and-real-world-applications" id="toc-societal-impact-and-real-world-applications" class="nav-link" data-scroll-target="#societal-impact-and-real-world-applications"><span class="header-section-number">11</span> Societal Impact and Real-World Applications</a></li>
  <li><a href="#ethical-considerations-and-responsible-ai-implementation" id="toc-ethical-considerations-and-responsible-ai-implementation" class="nav-link" data-scroll-target="#ethical-considerations-and-responsible-ai-implementation"><span class="header-section-number">12</span> Ethical Considerations and Responsible AI Implementation</a></li>
  <li><a href="#sec-proposal-lit-review" id="toc-sec-proposal-lit-review" class="nav-link" data-scroll-target="#sec-proposal-lit-review"><span class="header-section-number">13</span> Literature Review</a>
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">13.1</span> Introduction</a></li>
  <li><a href="#technical-background" id="toc-technical-background" class="nav-link" data-scroll-target="#technical-background"><span class="header-section-number">13.2</span> Technical Background</a></li>
  <li><a href="#empirical-evidence-and-performance-evaluation-of-rag-systems" id="toc-empirical-evidence-and-performance-evaluation-of-rag-systems" class="nav-link" data-scroll-target="#empirical-evidence-and-performance-evaluation-of-rag-systems"><span class="header-section-number">13.3</span> Empirical Evidence and Performance Evaluation of RAG Systems</a></li>
  <li><a href="#applications-in-systematic-reviews-and-evidence-synthesis" id="toc-applications-in-systematic-reviews-and-evidence-synthesis" class="nav-link" data-scroll-target="#applications-in-systematic-reviews-and-evidence-synthesis"><span class="header-section-number">13.4</span> Applications in Systematic Reviews and Evidence Synthesis</a></li>
  <li><a href="#applications-in-public-health-and-epidemiology" id="toc-applications-in-public-health-and-epidemiology" class="nav-link" data-scroll-target="#applications-in-public-health-and-epidemiology"><span class="header-section-number">13.5</span> Applications in Public Health and Epidemiology</a></li>
  <li><a href="#identification-of-methodological-gaps-using-retrieval-augmented-generation" id="toc-identification-of-methodological-gaps-using-retrieval-augmented-generation" class="nav-link" data-scroll-target="#identification-of-methodological-gaps-using-retrieval-augmented-generation"><span class="header-section-number">13.6</span> Identification of Methodological Gaps using Retrieval-Augmented Generation</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion"><span class="header-section-number">13.7</span> Discussion</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">13.8</span> Conclusion</a></li>
  <li><a href="#future-directions" id="toc-future-directions" class="nav-link" data-scroll-target="#future-directions"><span class="header-section-number">13.9</span> Future Directions</a></li>
  </ul></li>
  <li><a href="#data-management" id="toc-data-management" class="nav-link" data-scroll-target="#data-management"><span class="header-section-number">14</span> Data Management</a>
  <ul>
  <li><a href="#scholarly-literature-corpus-for-aim-1" id="toc-scholarly-literature-corpus-for-aim-1" class="nav-link" data-scroll-target="#scholarly-literature-corpus-for-aim-1"><span class="header-section-number">14.1</span> Scholarly Literature Corpus (for Aim 1)</a></li>
  <li><a href="#public-health-and-environmental-datasets-for-aim-2" id="toc-public-health-and-environmental-datasets-for-aim-2" class="nav-link" data-scroll-target="#public-health-and-environmental-datasets-for-aim-2"><span class="header-section-number">14.2</span> Public Health and Environmental Datasets (for Aim 2)</a></li>
  <li><a href="#geospatial-and-remote-sensing-imagery-for-aim-3" id="toc-geospatial-and-remote-sensing-imagery-for-aim-3" class="nav-link" data-scroll-target="#geospatial-and-remote-sensing-imagery-for-aim-3"><span class="header-section-number">14.3</span> Geospatial and Remote Sensing Imagery (for Aim 3)</a></li>
  </ul></li>
  <li><a href="#expected-results" id="toc-expected-results" class="nav-link" data-scroll-target="#expected-results"><span class="header-section-number">15</span> Expected Results</a>
  <ul>
  <li><a href="#a-novel-ai-powered-literature-analysis-pipeline-from-aim-1" id="toc-a-novel-ai-powered-literature-analysis-pipeline-from-aim-1" class="nav-link" data-scroll-target="#a-novel-ai-powered-literature-analysis-pipeline-from-aim-1"><span class="header-section-number">15.1</span> A Novel AI-Powered Literature Analysis Pipeline (from Aim 1)</a></li>
  <li><a href="#a-baseline-model-of-ozones-impact-on-cardiovascular-health-from-aim-2" id="toc-a-baseline-model-of-ozones-impact-on-cardiovascular-health-from-aim-2" class="nav-link" data-scroll-target="#a-baseline-model-of-ozones-impact-on-cardiovascular-health-from-aim-2"><span class="header-section-number">15.2</span> A Baseline Model of Ozone’s Impact on Cardiovascular Health (from Aim 2)</a></li>
  <li><a href="#a-state-of-the-art-framework-and-inventory-for-uog-monitoring-from-aim-3" id="toc-a-state-of-the-art-framework-and-inventory-for-uog-monitoring-from-aim-3" class="nav-link" data-scroll-target="#a-state-of-the-art-framework-and-inventory-for-uog-monitoring-from-aim-3"><span class="header-section-number">15.3</span> A State-of-the-Art Framework and Inventory for UOG Monitoring (from Aim 3)</a></li>
  <li><a href="#comprehensive-documentation-and-dissemination" id="toc-comprehensive-documentation-and-dissemination" class="nav-link" data-scroll-target="#comprehensive-documentation-and-dissemination"><span class="header-section-number">15.4</span> Comprehensive Documentation and Dissemination</a></li>
  </ul></li>
  <li><a href="#example-data-extraction-functions" id="toc-example-data-extraction-functions" class="nav-link" data-scroll-target="#example-data-extraction-functions"><span class="header-section-number">16</span> Example data extraction functions</a>
  <ul>
  <li><a href="#module-fast_pubmed.py" id="toc-module-fast_pubmed.py" class="nav-link" data-scroll-target="#module-fast_pubmed.py"><span class="header-section-number">16.1</span> Module: <code>fast_pubmed.py</code></a></li>
  <li><a href="#module-fast_openalex.py" id="toc-module-fast_openalex.py" class="nav-link" data-scroll-target="#module-fast_openalex.py"><span class="header-section-number">16.2</span> Module: <code>fast_openalex.py</code></a></li>
  <li><a href="#module-etl_elsevier.py" id="toc-module-etl_elsevier.py" class="nav-link" data-scroll-target="#module-etl_elsevier.py"><span class="header-section-number">16.3</span> Module: <code>etl_elsevier.py</code></a></li>
  <li><a href="#module-async_unpaywall.py" id="toc-module-async_unpaywall.py" class="nav-link" data-scroll-target="#module-async_unpaywall.py"><span class="header-section-number">16.4</span> Module: <code>async_unpaywall.py</code></a></li>
  <li><a href="#module-docling_extract_formulas_mp_multi.py" id="toc-module-docling_extract_formulas_mp_multi.py" class="nav-link" data-scroll-target="#module-docling_extract_formulas_mp_multi.py"><span class="header-section-number">16.5</span> Module <code>docling_extract_formulas_mp_multi.py</code></a></li>
  <li><a href="#module-fast_zotero.py" id="toc-module-fast_zotero.py" class="nav-link" data-scroll-target="#module-fast_zotero.py"><span class="header-section-number">16.6</span> Module: <code>fast_zotero.py</code></a></li>
  <li><a href="#module-field_extraction.py" id="toc-module-field_extraction.py" class="nav-link" data-scroll-target="#module-field_extraction.py"><span class="header-section-number">16.7</span> Module: <code>field_extraction.py</code></a></li>
  <li><a href="#module-topic_modeling_gui.py" id="toc-module-topic_modeling_gui.py" class="nav-link" data-scroll-target="#module-topic_modeling_gui.py"><span class="header-section-number">16.8</span> Module: <code>topic_modeling_gui.py</code></a></li>
  <li><a href="#module-kg_pipeline.py" id="toc-module-kg_pipeline.py" class="nav-link" data-scroll-target="#module-kg_pipeline.py"><span class="header-section-number">16.9</span> Module: <code>kg_pipeline.py</code></a></li>
  <li><a href="#module-dictionaries.py" id="toc-module-dictionaries.py" class="nav-link" data-scroll-target="#module-dictionaries.py"><span class="header-section-number">16.10</span> Module: <code>dictionaries.py</code></a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">17</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Literature Analytics and Methodological Gap Analysis in Geospatial Epidemiology</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Alex Godinez </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 13, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>#01-proposal.qmd</p>
<p><strong>Working Title</strong>:<br>
“AI-Powered ETL &amp; RAG System for Large-Scale Academic Literature Analytics and Methodological Gap Analysis in Geospatial Epidemiology”</p>
<hr>
<section id="overall-goal" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Overall Goal</h1>
<p>I aim to create and execute an end-to-end research program that will:</p>
<ol type="1">
<li><p><strong>Develop an AI-Powered Pipeline (Aim 1)</strong>: Engineer an automated system combining Extract, Transform, Load (ETL) and Retrieval-Augmented Generation (RAG) to systematically analyze scientific literature and identify methodological research gaps.</p></li>
<li><p><strong>Conduct a Baseline Analysis (Aim 2)</strong>: Apply established machine learning techniques (e.g., Random Forest) to a well-defined environmental health question (ozone and cardiovascular disease) informed by the pipeline’s findings.</p></li>
<li><p><strong>Innovate with Advanced Deep Learning (Aim 3)</strong>: Address a key identified gap by developing and validating a novel deep learning framework (CNNs and GNNs) to tackle a challenging, high-impact problem—the large-scale identification and activity monitoring of unconventional oil and gas (UOG) development sites using satellite data.</p></li>
</ol>
<p>The core objective is to demonstrate a complete research lifecycle: from AI-driven gap identification to baseline analysis, and culminating in the application of cutting-edge methods to create a new, foundational dataset for environmental health research.</p>
<hr>
</section>
<section id="specific-aims-and-research-questions" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Specific Aims and Research Questions</h1>
<p>This dissertation is structured around three specific research aims:</p>
<p><strong>Specific Aim 1: Develop an AI-Powered System for Methodological Gap Analysis.</strong> This aim focuses on the engineering and validation of the ETL+RAG pipeline, a tool designed to systematically process scientific literature and identify under-explored research methodologies in data-intensive fields.</p>
<p><strong>Specific Aim 2: Analyze the Association Between Ozone Exposure and Cardiovascular Disease Mortality.</strong> This aim serves as a direct application of the pipeline. It involves conducting a systematic literature review to confirm the state of the science and then applying a baseline machine learning analysis (Random Forest) to a large-scale CDC dataset to explore the link between ozone and CVD mortality.</p>
<ul>
<li><strong>Research Question:</strong> To what extent do annual ozone exposure metrics predict county-level cardiovascular mortality rates in the U.S. after controlling for key covariates?</li>
</ul>
<p><strong>Specific Aim 3: Develop a Deep Learning Framework for Monitoring Unconventional Oil and Gas Development.</strong> Addressing the methodological gap identified by Aim 1, this aim involves creating a novel framework using CNNs and GNNs to identify UOG sites and monitor their activity via satellite data.</p>
<ul>
<li><strong>Research Question:</strong> Can a multi-modal deep learning framework, integrating high-resolution optical and methane satellite data, accurately identify and classify the activity status of UOG wells? Can the resulting inventory be used to explore associations with public health outcomes?</li>
</ul>
</section>
<section id="proposed-methodology-for-aim-3" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Proposed Methodology for Aim 3</h1>
<p>The framework for Aim 3 will leverage <strong>Convolutional Neural Networks (CNNs)</strong> to analyze <strong>multi-modal satellite imagery</strong> (e.g., high-resolution optical, Sentinel-5P methane data) for object detection and classification. The goal is to move beyond simple site identification and create a detailed, actionable inventory of UOG infrastructure. As illustrated in the conceptual example <a href="05-aim3.html#fig-well-concept" class="quarto-xref">Figure&nbsp;<span>14.1</span></a>, the model will be trained to identify key components within a well site, such as:</p>
<div id="fig-well-concept" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-well-concept-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures\contrst.PNG" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-well-concept-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.1: Well pad Concept
</figcaption>
</figure>
</div>
<ul>
<li><strong>Well pad</strong> (yellow)<br>
</li>
<li><strong>Storage tanks</strong> (purple)<br>
</li>
<li><strong>Vehicle fleets</strong> (red)</li>
</ul>
<p>These components serve as proxies for site activity levels.</p>
<hr>
<p>To dramatically improve computational efficiency and model performance, a novel <strong>pre-processing step</strong> will be implemented:</p>
<ol type="1">
<li><strong>Mask creation</strong>
<ul>
<li>Leverage publicly available county tax parcel data<br>
</li>
<li>Programmatically exclude areas where UOG development is highly improbable (residential zones, protected lands, commercial districts)</li>
</ul></li>
<li><strong>Focused analysis</strong>
<ul>
<li>Significantly reduce the geographic search space<br>
</li>
<li>Enable more intensive modeling on the remaining, high-likelihood parcels</li>
</ul></li>
</ol>
<hr>
<p>The final output will be a comprehensive, geolocated dataset of UOG sites and their components, which is essential for future environmental exposure and health impact studies.</p>
<p>A complete, detailed breakdown of this methodology, including the phased implementation plan and specific model architectures, is provided in the chapter on the <a href="./05-aim3.html#sec-aim-three">Proposed Deep Learning Framework for UOG Site Monitoring (Aim 3)</a>.</p>
</section>
<section id="application-scenario" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Application Scenario</h1>
<p><strong>As a first application to validate the pipeline (Aim 1), the ETL &amp; RAG system will facilitate</strong> a systematic review of research intersecting:</p>
<ul>
<li>Ozone exposure and health outcomes (heart disease).</li>
<li>Geospatial epidemiological techniques.</li>
<li>Machine learning methodologies.</li>
</ul>
<p>Through semantic querying, the pipeline will explicitly reveal:</p>
<ul>
<li>Commonly applied geospatial analysis techniques (spatial regression, kriging, hotspot analysis).</li>
<li>Prevalent machine learning methods (Random Forest, XGBoost, Neural Networks).</li>
<li>Underrepresented or novel methodologies within existing literature.</li>
</ul>
<p><strong>The insights gained from this initial review will directly inform the baseline analysis in Aim 2 and the selection of advanced deep learning methods for the novel framework in Aim 3</strong>, demonstrating the value of the ETL and RAG tools in launching a multi-stage research program.</p>
<hr>
</section>
<section id="personal-motivation-investment" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Personal Motivation &amp; Investment</h1>
<p>Manual literature reviews and data extraction are notoriously time-consuming. Recognizing these limitations, and anticipating the computational demands of the proposed research aims, I personally invested in specialized hardware (multiple GPUs, 512 GB RAM, upgraded motherboard). This local high-performance computing environment is essential for handling the full scope of this dissertation, including: <strong>large-scale PDF processing for Aim 1; geospatial analysis and ML model training for Aim 2; and, most critically, the development and training of state-of-the-art deep learning models for Aim 3, which involves processing vast satellite imagery datasets and multi-modal data streams (optical, methane, vector).</strong></p>
<p>This investment reduces reliance on restrictive university cluster computing protocols and costly API services, ensuring the economic and logistical sustainability required for a project of this scale and complexity.</p>
<hr>
</section>
<section id="why-its-interesting" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Why It’s Interesting</h1>
<ul>
<li><strong>Interdisciplinary Impact</strong>: Applicable to diverse research domains beyond epidemiology and environmental health.</li>
<li><strong>Innovation Alignment</strong>: The focus on AI-driven geospatial analysis is potentially valuable to institutions such as UAlbany’s AI Plus Institute.</li>
<li><strong>Flexible Framework</strong>: Easily adaptable for analyzing unstructured datasets outside academic literature.</li>
<li><strong>Novel Environmental Monitoring:</strong> <strong>Introduces a state-of-the-art deep learning framework for monitoring industrial activity at a national scale, creating a new, publicly valuable dataset for environmental health research and policy.</strong></li>
</ul>
<hr>
</section>
<section id="timeline" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Timeline</h1>
<p>This dissertation is structured across three primary aims, with a projected timeline spanning approximately two academic years.</p>
<p><strong>Year 1, Semester 1</strong></p>
<ul>
<li><p><strong>Primary Aim:</strong> Aim 1</p></li>
<li><p><strong>Tasks:</strong> Finalize ETL+RAG pipeline development, complete GUI, conduct large-scale literature ingestion for ozone-CVD review</p></li>
</ul>
<p><strong>Year 1, Semester 2</strong></p>
<ul>
<li><p><strong>Primary Aim:</strong> Aim 2</p></li>
<li><p><strong>Tasks:</strong> Perform preliminary analysis of ozone-CVD data, write up literature review (Chapter 3) and baseline analysis (Chapter 4).</p></li>
</ul>
<p><strong>Year 2, Semester 1</strong></p>
<ul>
<li><p><strong>Primary Aim:</strong> Aim 3</p></li>
<li><p><strong>Tasks:</strong> Acquire and preprocess optical and methane satellite data. Develop, train, and validate the CNN model for UOG site identification.</p></li>
</ul>
<p><strong>Year 2, Semester 2</strong></p>
<ul>
<li><p><strong>Primary Aim:</strong> Aim 3</p></li>
<li><p><strong>Tasks:</strong> Integrate methane data for activity classification. Develop GNN framework for analysis. Finalize analysis and write-up of Aim 3.</p></li>
</ul>
<p><strong>Final Months</strong></p>
<ul>
<li><strong>All Aims</strong> Synthesize all chapters, complete final dissertation document, and prepare for defense.</li>
</ul>
<hr>
</section>
<section id="interdisciplinary-collaboration-and-cross-domain-utility" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Interdisciplinary Collaboration and Cross-Domain Utility</h1>
<p>Retrieval-Augmented Generation (RAG) facilitates interdisciplinary research by connecting knowledge domains through new data incorporation during generation (<span class="citation" data-cites="luu_bioinspiredllm_2023">Luu and Buehler (<a href="#ref-luu_bioinspiredllm_2023" role="doc-biblioref">2023</a>)</span>). RAG-powered academic search tools enable complex, natural language queries, improving cross-field literature synthesis over traditional methods (<span class="citation" data-cites="j_bolanos_artificial_2024">J. Bolaños et al. (<a href="#ref-j_bolanos_artificial_2024" role="doc-biblioref">2024</a>)</span>). RAG’s integration into LLMs enhances their adaptability for diverse research applications <span class="citation" data-cites="lee_bring_2024">(<a href="#ref-lee_bring_2024" role="doc-biblioref">Lee and Kim 2024</a>)</span>, demonstrated by systems that retrieve precise COVID-19 health information (<span class="citation" data-cites="upadhyayEnhancingHealthInformation2025">Upadhyay and Viviani (<a href="#ref-upadhyayEnhancingHealthInformation2025" role="doc-biblioref">2025</a>)</span>) or integrate findings on sustainable biomaterials.</p>
<p>Knowledge graph-based methods promote interdisciplinary collaboration by mapping research concepts across domains via graph mining in literature analytics (<span class="citation" data-cites="j_bolanos_artificial_2024">J. Bolaños et al. (<a href="#ref-j_bolanos_artificial_2024" role="doc-biblioref">2024</a>)</span>). Platforms like NetMe 2.0 create interactive knowledge graphs from biomedical literature, allowing shared exploration of connections by diverse specialists (<span class="citation" data-cites="di_maria_netme_2024">Di Maria et al. (<a href="#ref-di_maria_netme_2024" role="doc-biblioref">2024</a>)</span>). Aligning LLMs with domain knowledge graphs improves multi-hop reasoning across distinct corpora (<span class="citation" data-cites="dernbach_glam_2024">Dernbach et al. (<a href="#ref-dernbach_glam_2024" role="doc-biblioref">2024</a>)</span>). Logic-Augmented Generation allows experts from multiple fields to collaboratively build and reconcile knowledge (<span class="citation" data-cites="gangemi_logic_2025">Gangemi and Giovanni Nuzzolese (<a href="#ref-gangemi_logic_2025" role="doc-biblioref">2025</a>)</span>). LLM-driven ontology creation also integrates varied datasets from different domains, such as urban systems, to improve interdisciplinary data sharing (<span class="citation" data-cites="tupayachi_towards_2024">Tupayachi et al. (<a href="#ref-tupayachi_towards_2024" role="doc-biblioref">2024</a>)</span>).</p>
<section id="interdisciplinary-impact-example" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="interdisciplinary-impact-example"><span class="header-section-number">10.1</span> Interdisciplinary Impact Example</h2>
<p>Beyond its application in geospatial epidemiology, the inherent flexibility of the AI-Powered ETL &amp; RAG system architecture makes it directly applicable to other complex, data-intensive research domains such as Life Cycle Assessment (LCA) for agricultural systems, particularly concerning cover crop GWP and the compilation of Life Cycle Inventories (LCI). The existing ETL pipeline (including fast_pubmed.py, fast_openalex.py) can be readily aimed at literature pertaining to LCA, GWP, and cover crop management. The core field_extraction.py module, configurable via etl_config.json and the project’s GUI (config_tab.py), is already equipped with extraction fields highly pertinent to LCA/LCI. Specifically, pre-defined fields such as “LCA System Boundaries”, “Environmental Impact Categories”, “Management Practices and Operational Details”, and the structured “Metrics” field (designed to capture {“Metric”: “name”, “Value”: “value”, “Unit”: “unit”}) are directly suited for systematically extracting quantitative LCI data (fertilizer inputs, fuel consumption, emission values, crop yields) and qualitative contextual information from a large corpus of relevant scientific articles.</p>
<p>The system’s capacity for knowledge structuration further enhances its utility for LCA/GWP research. The extensive existing knowledge base, comprising over 25 dictionaries with approximately 10,000 synonyms managed via dictionaries_gui.py (from dictionaries_config.json), includes relevant lexicons like “AGRONOMIC_MGMT_PRACTICES_SYNONYMS”, “ENVIRONMENTAL_IMPACT_CATEGORIES”, “COVER_CROP_SYNONYMS”, and “SOIL_TYPE_SYNONYMS”. These require only clicking a few checkboxes for LCA-specific terminology (specific LCI flow names, impact assessment methods, GWP characterization factors) within the GUI rather than development from scratch. The extracted and semantically unified data, including detailed LCI parameters and GWP values, is then processed by kg_pipeline.py to construct a domain-specific knowledge graph. This KG can serve as a queryable, literature-derived database of LCI components and GWP factors, enabling systematic comparison of different cover crop systems, validation of LCI data, and benchmarking of GWP model results, such as those from the previously developed Random Forest analysis for GWP_Total.</p>
<p>This application to LCA/GWP research effectively demonstrates the system’s broader “Interdisciplinary Impact” and its function as a “Flexible Framework” capable of large-scale, structured data extraction and analysis from scientific literature across diverse domains. By selecting fields within the GUI to prioritize LCA-relevant fields and refining the domain-specific dictionaries, the pipeline can efficiently build a comprehensive knowledge base to support detailed LCA studies and contextualize empirical GWP findings. This not only addresses specific research needs within agricultural systems analysis but also validates the core design principles of the ETL+RAG system for robust and adaptable automated literature analytics.</p>
<hr>
</section>
</section>
<section id="societal-impact-and-real-world-applications" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Societal Impact and Real-World Applications</h1>
<p>AI-driven literature review systems provide societal benefits in public health and epidemiology by accelerating research timelines. For example, AI reduced data extraction time for a diabetic retinopathy review from 1,310 minutes to 5 minutes (<span class="citation" data-cites="gue_evaluating_2024">Gue et al. (<a href="#ref-gue_evaluating_2024" role="doc-biblioref">2024</a>)</span>), and an LLM completed a literature review in 17 hours compared to 100 hours for humans (<span class="citation" data-cites="tsai_comparative_2024">Tsai, Huang, and Kuo (<a href="#ref-tsai_comparative_2024" role="doc-biblioref">2024</a>)</span>). This efficiency supports quicker synthesis of findings that can influence policy development (<span class="citation" data-cites="j_bolanos_artificial_2024">J. Bolaños et al. (<a href="#ref-j_bolanos_artificial_2024" role="doc-biblioref">2024</a>)</span>). AI screening also minimizes costs while preserving high recall in evidence synthesis. These systems maintain high accuracy, with GPT-4 achieving 99% reviewer accuracy in systematic review tasks (<span class="citation" data-cites="fleurence_generative_2024">Fleurence et al. (<a href="#ref-fleurence_generative_2024" role="doc-biblioref">2024a</a>)</span>). Retrieval-Augmented Generation (RAG) contributes by enhancing AI output reliability and factuality. A RAG system achieved 86% diagnostic accuracy and 95% accuracy in citing sources, aiding hallucination detection (<span class="citation" data-cites="tozuka_application_2024">Tozuka et al. (<a href="#ref-tozuka_application_2024" role="doc-biblioref">2024</a>)</span>). RAG is a recognized strategy to mitigate hallucinations, improve factuality (<span class="citation" data-cites="huangSurveyHallucinationLarge2024">Huang et al. (<a href="#ref-huangSurveyHallucinationLarge2024" role="doc-biblioref">2024</a>)</span>; <span class="citation" data-cites="aditya_understanding_2024">Aditya (<a href="#ref-aditya_understanding_2024" role="doc-biblioref">2024</a>)</span>), and enhance topical relevance with factual accuracy in health information retrieval <span class="citation" data-cites="upadhyayEnhancingHealthInformation2025">(<a href="#ref-upadhyayEnhancingHealthInformation2025" role="doc-biblioref">Upadhyay and Viviani 2025</a>)</span>.</p>
<hr>
</section>
<section id="ethical-considerations-and-responsible-ai-implementation" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Ethical Considerations and Responsible AI Implementation</h1>
<p>Automated literature extraction and synthesis systems raise specific ethical issues requiring careful management. Transparency, risk classification, and fairness-accountability-transparency-ethics (FATE) measures are necessary, aligning with regulations like the EU AI Act (<span class="citation" data-cites="j_bolanos_artificial_2024">J. Bolaños et al. (<a href="#ref-j_bolanos_artificial_2024" role="doc-biblioref">2024</a>)</span>). Systems require explicit bias mitigation strategies to prevent skewed evidence bases from automated screening (<span class="citation" data-cites="tsai_comparative_2024">Tsai, Huang, and Kuo (<a href="#ref-tsai_comparative_2024" role="doc-biblioref">2024</a>)</span>). The use of generative AI for scholarly tasks underscores the need for formal ethical guidelines and researcher training (<span class="citation" data-cites="yuan_leveraging_2024">Yuan et al. (<a href="#ref-yuan_leveraging_2024" role="doc-biblioref">2024</a>)</span>). Factual inaccuracies and hallucinations in foundation models present threats to scientific rigor if not addressed (<span class="citation" data-cites="fleurence_generative_2024">Fleurence et al. (<a href="#ref-fleurence_generative_2024" role="doc-biblioref">2024a</a>)</span>). Additionally, these systems pose privacy and data protection challenges due to the risk of large models memorizing and reproducing sensitive data, necessitating compliance with HIPAA, GDPR, and the EU AI Act.</p>
<hr>
</section>
<section id="sec-proposal-lit-review" class="level1" data-number="13">
<h1 data-number="13"><span class="header-section-number">13</span> Literature Review</h1>
<div id="fig-graph-abstract" class="quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-graph-abstract-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/ETL_RAG.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-graph-abstract-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13.1: Graphical Abstract
</figcaption>
</figure>
</div>
<section id="introduction" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">13.1</span> Introduction</h2>
<p>Retrieval-Augmented Generation (RAG) is a machine-learning framework combining information retrieval with deep-learning models, such as transformer-based large language models <span class="citation" data-cites="rawsonNgaAraWhakamana2024">(<a href="#ref-rawsonNgaAraWhakamana2024" role="doc-biblioref">Rawson 2024</a>)</span>. This approach enhances factual accuracy, coherence, and context relevance of generated responses by incorporating retrieved information into the generation process <span class="citation" data-cites="liAugmentingLargeLanguage2024">(<a href="#ref-liAugmentingLargeLanguage2024" role="doc-biblioref">Li and Lai 2024</a>)</span>. Within geospatial epidemiology, particularly concerning ozone exposure and heart disease, RAG offers a tool for synthesizing spatial and temporal data from environmental and health datasets. By integrating parametric memory of large language models with non-parametric external knowledge bases, RAG supports researchers. For example, RAG can help identify critical knowledge gaps and underrepresented methodologies <span class="citation" data-cites="barnettSevenFailurePoints2024">(<a href="#ref-barnettSevenFailurePoints2024" role="doc-biblioref">Barnett et al. 2024</a>)</span>, and improve the factual accuracy of health information <span class="citation" data-cites="upadhyayEnhancingHealthInformation2025">(<a href="#ref-upadhyayEnhancingHealthInformation2025" role="doc-biblioref">Upadhyay and Viviani 2025</a>)</span>, advancing the understanding of chronic disease risk factors.</p>
</section>
<section id="technical-background" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="technical-background"><span class="header-section-number">13.2</span> Technical Background</h2>
<p>RAG combines deep learning with traditional information retrieval, integrating parametric and non-parametric memory systems to enhance text generation accuracy. The parametric component involves transformer-based neural models, such as sequence-to-sequence architectures (BART, T5, LLaMA), that store learned information within model weights and can be fine-tuned for specific tasks <span class="citation" data-cites="rawsonNgaAraWhakamana2024 fengRetrievalGenerationSynergyAugmented2024">(<a href="#ref-rawsonNgaAraWhakamana2024" role="doc-biblioref">Rawson 2024</a>; <a href="#ref-fengRetrievalGenerationSynergyAugmented2024" role="doc-biblioref">Feng et al. 2024</a>)</span>. Non-parametric memory relies on external databases indexed as dense vector representations, queried using neural retrievers like Dense Passage Retriever (DPR) or dual-encoder architectures, enabling retrieval of contextually relevant information without model retraining <span class="citation" data-cites="rawsonNgaAraWhakamana2024 sakarMaximizingRAGEfficiency2024">(<a href="#ref-rawsonNgaAraWhakamana2024" role="doc-biblioref">Rawson 2024</a>; <a href="#ref-sakarMaximizingRAGEfficiency2024" role="doc-biblioref">Şakar and Emekci 2024</a>)</span>. Transformer-based architectures are employed in RAG pipelines for their language modeling capabilities, facilitating coherent and contextually informed responses. The combination of transformer generators and retrieval encoders improves accuracy, relevance, and freshness of generated content by leveraging external, updateable knowledge bases <span class="citation" data-cites="fanSurveyRAGMeeting2024 wangSearchingBestPractices2024">(<a href="#ref-fanSurveyRAGMeeting2024" role="doc-biblioref">Fan et al. 2024</a>; <a href="#ref-wangSearchingBestPractices2024" role="doc-biblioref">Wang et al. 2024</a>)</span>. RAG systems bridge gaps between static, trained model knowledge and evolving external data sources, often outperforming traditional NLP methods in factual precision and resource efficiency <span class="citation" data-cites="liAugmentingLargeLanguage2024 upadhyayEnhancingHealthInformation2025">(<a href="#ref-liAugmentingLargeLanguage2024" role="doc-biblioref">Li and Lai 2024</a>; <a href="#ref-upadhyayEnhancingHealthInformation2025" role="doc-biblioref">Upadhyay and Viviani 2025</a>)</span>.</p>
</section>
<section id="empirical-evidence-and-performance-evaluation-of-rag-systems" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="empirical-evidence-and-performance-evaluation-of-rag-systems"><span class="header-section-number">13.3</span> Empirical Evidence and Performance Evaluation of RAG Systems</h2>
<p>Empirical evaluation of RAG assesses its enhancement of factual accuracy, retrieval effectiveness, and efficiency in text generation. Studies like <span class="citation" data-cites="fatehaliAutomatedLiteratureReview2024">Fateh Ali et al. (<a href="#ref-fatehaliAutomatedLiteratureReview2024" role="doc-biblioref">2024</a>)</span> compared RAG-based pipelines against conventional NLP approaches, including transformer-only models and frequency-based topic modeling, finding RAG superior based on higher ROUGE-1 (0.364) and ROUGE-2 (0.123) scores. <span class="citation" data-cites="upadhyayEnhancingHealthInformation2025">Upadhyay and Viviani (<a href="#ref-upadhyayEnhancingHealthInformation2025" role="doc-biblioref">2025</a>)</span> demonstrated RAG’s effectiveness in health-information retrieval, nearly doubling performance metrics like CAM NDCG (0.2146 vs.&nbsp;0.1119) and CAM MAP (0.1079 vs.&nbsp;0.0455) compared to non-RAG systems. A central hypothesis is that integrating retrieval with generation boosts the accuracy, reliability, and contextual relevance of outputs.</p>
<p>Studies employed experimental designs comparing RAG models with multiple baselines, including transformer-based models (T5, GPT-3.5), frequency-based methods (spaCy), and traditional IR techniques (BM25). Data sources included academic corpora, scientific literature collections, and clinical notes, selected for relevance, quality, and representativeness <span class="citation" data-cites="liAugmentingLargeLanguage2024 rawsonNgaAraWhakamana2024 shah-mohammadiUtilizingRAGGPT42024">(<a href="#ref-liAugmentingLargeLanguage2024" role="doc-biblioref">Li and Lai 2024</a>; <a href="#ref-rawsonNgaAraWhakamana2024" role="doc-biblioref">Rawson 2024</a>; <a href="#ref-shah-mohammadiUtilizingRAGGPT42024" role="doc-biblioref">Shah-Mohammadi and Finkelstein 2024</a>)</span>. Common evaluation metrics included ROUGE scores, precision, recall, F1-scores, CAM-MAP, and CAM-NDCG, assessing textual relevance, accuracy, and coherence.</p>
<p>Quantitative results from empirical studies indicate RAG’s improved performance in generating contextually accurate and relevant outputs. For example, <span class="citation" data-cites="kreimeyerUsingRetrievalAugmentedGeneration2024">Kreimeyer et al. (<a href="#ref-kreimeyerUsingRetrievalAugmentedGeneration2024" role="doc-biblioref">2024</a>)</span> reported RAG reproducing over 80% of expert-curated information in oncology literature, indicating reliability and precision. <span class="citation" data-cites="guProbabilisticMedicalPredictions2024">Gu et al. (<a href="#ref-guProbabilisticMedicalPredictions2024" role="doc-biblioref">2024</a>)</span> demonstrated RAG’s efficiency gains by reducing manual systematic review extraction time from 1.310 minutes to 5 minutes, without sacrificing data quality. These studies highlight RAG’s strengths but also emphasize managing retrieval parameters (e.g., chunk size, embedding strategies) to avoid retrieval inaccuracies or context misalignment <span class="citation" data-cites="barnettSevenFailurePoints2024">(<a href="#ref-barnettSevenFailurePoints2024" role="doc-biblioref">Barnett et al. 2024</a>)</span>.</p>
</section>
<section id="applications-in-systematic-reviews-and-evidence-synthesis" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="applications-in-systematic-reviews-and-evidence-synthesis"><span class="header-section-number">13.4</span> Applications in Systematic Reviews and Evidence Synthesis</h2>
<p>RAG streamlines evidence collection in systematic reviews by combining parametric and non-parametric memory systems. These systems pair neural sequence-to-sequence generators with dense-vector indices queried by neural retrievers, automating the identification and extraction of relevant literature <span class="citation" data-cites="rawsonNgaAraWhakamana2024 sakarMaximizingRAGEfficiency2024">(<a href="#ref-rawsonNgaAraWhakamana2024" role="doc-biblioref">Rawson 2024</a>; <a href="#ref-sakarMaximizingRAGEfficiency2024" role="doc-biblioref">Şakar and Emekci 2024</a>)</span>. This automation reduces the manual workload associated with literature screening and data extraction. For instance, GPT-3.5 Turbo with RAG reduced data extraction time in systematic reviews from 1,310 minutes to 5 minutes, maintaining high concordance with human reviewers for extracting structured data <span class="citation" data-cites="guProbabilisticMedicalPredictions2024">(<a href="#ref-guProbabilisticMedicalPredictions2024" role="doc-biblioref">Gu et al. 2024</a>)</span>.</p>
<p>RAG also enhances the accuracy and consistency of data extraction processes. In health information retrieval tasks, RAG-driven models demonstrated improved topical relevance and factual accuracy, with improved performance metrics such as CAM-MAP and CAM-NDCG compared to traditional information retrieval methods <span class="citation" data-cites="upadhyayEnhancingHealthInformation2025">(<a href="#ref-upadhyayEnhancingHealthInformation2025" role="doc-biblioref">Upadhyay and Viviani 2025</a>)</span>. Furthermore, RAG with quantized LLMs improves data extraction accuracy (exceeding 93%) while reducing computational resource demands <span class="citation" data-cites="ranjanmaharanaRetrievalAugmentedGeneration2024">(<a href="#ref-ranjanmaharanaRetrievalAugmentedGeneration2024" role="doc-biblioref">Ranjan Maharana and Joshi 2024</a>)</span>. These approaches improve efficiency and can mitigate human biases, aiding uniformity in evidence synthesis.</p>
<p>Advanced RAG implementations in systematic reviews leverage semantic search capabilities through dense-vector indices and neural retrieval methods. This approach often retrieves literature with greater contextual understanding than conventional keyword-based searches. When such retrieval is combined with large language models for generation, it can support the identification of relevant and potentially overlooked literature. Recent empirical studies illustrate that integrating RAG into literature review processes yields better summarization accuracy, with measurable improvements in ROUGE metrics compared to other NLP methods <span class="citation" data-cites="fatehaliAutomatedLiteratureReview2024">(<a href="#ref-fatehaliAutomatedLiteratureReview2024" role="doc-biblioref">Fateh Ali et al. 2024</a>)</span>. This demonstrates RAG’s capability to provide accurate, contextually relevant summaries for high-quality evidence synthesis.</p>
</section>
<section id="applications-in-public-health-and-epidemiology" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="applications-in-public-health-and-epidemiology"><span class="header-section-number">13.5</span> Applications in Public Health and Epidemiology</h2>
<p>RAG applications in Public Health and Epidemiology enhance information synthesis and decision-making. RAG systems ground responses in current, domain-specific evidence by incorporating information from diverse sources like clinical guidelines and surveillance data, improving factual accuracy <span class="citation" data-cites="rawsonNgaAraWhakamana2024 liAugmentingLargeLanguage2024">(<a href="#ref-rawsonNgaAraWhakamana2024" role="doc-biblioref">Rawson 2024</a>; <a href="#ref-liAugmentingLargeLanguage2024" role="doc-biblioref">Li and Lai 2024</a>)</span>. This capability aids public health professionals in synthesizing evolving information for interventions. Examples include updating knowledge bases for health worker training <span class="citation" data-cites="alghadbanTransformingHealthcareEducation2023">(<a href="#ref-alghadbanTransformingHealthcareEducation2023" role="doc-biblioref">Al Ghadban et al. 2023</a>)</span>, streamlining surveillance via clinical note data extraction <span class="citation" data-cites="shah-mohammadiUtilizingRAGGPT42024">(<a href="#ref-shah-mohammadiUtilizingRAGGPT42024" role="doc-biblioref">Shah-Mohammadi and Finkelstein 2024</a>)</span>, and processing large document sets for key point summarization with tools like ‘Cognitive Reviewer’ <span class="citation" data-cites="barnettSevenFailurePoints2024">(<a href="#ref-barnettSevenFailurePoints2024" role="doc-biblioref">Barnett et al. 2024</a>)</span>. RAG also automates accurate structured dataset creation from literature <span class="citation" data-cites="ranjanmaharanaRetrievalAugmentedGeneration2024">(<a href="#ref-ranjanmaharanaRetrievalAugmentedGeneration2024" role="doc-biblioref">Ranjan Maharana and Joshi 2024</a>)</span>. Policy experts recognize RAG for improving accuracy in evidence synthesis <span class="citation" data-cites="fleurenceGenerativeAIHealth2024a">(<a href="#ref-fleurenceGenerativeAIHealth2024a" role="doc-biblioref">Fleurence et al. 2024b</a>)</span>.</p>
<p>In health communication and public engagement, RAG contributes to generating clear, accurate, and personalized health information. For instance, RAG integrated into models for breast-cancer nursing care questions yielded high user-rated accuracy and empathy <span class="citation" data-cites="xuEvaluationIntegrationRetrievalaugmented2024">(<a href="#ref-xuEvaluationIntegrationRetrievalaugmented2024" role="doc-biblioref">R. Xu et al. 2024</a>)</span>. RAG-driven systems are also used to train frontline health workers by providing traceable, guideline-based information adaptable to evolving clinical knowledge <span class="citation" data-cites="alghadbanTransformingHealthcareEducation2023">(<a href="#ref-alghadbanTransformingHealthcareEducation2023" role="doc-biblioref">Al Ghadban et al. 2023</a>)</span>. By enhancing topical relevance and factual accuracy in consumer health information retrieval and constraining hallucinations, RAG contributes to reliable health education and efforts against misinformation <span class="citation" data-cites="upadhyayEnhancingHealthInformation2025">(<a href="#ref-upadhyayEnhancingHealthInformation2025" role="doc-biblioref">Upadhyay and Viviani 2025</a>)</span>.</p>
</section>
<section id="identification-of-methodological-gaps-using-retrieval-augmented-generation" class="level2" data-number="13.6">
<h2 data-number="13.6" class="anchored" data-anchor-id="identification-of-methodological-gaps-using-retrieval-augmented-generation"><span class="header-section-number">13.6</span> Identification of Methodological Gaps using Retrieval-Augmented Generation</h2>
<p>RAG can be a meta-analytic tool to identify methodological gaps by processing scientific literature. RAG deployments map ‘failure points’ in various workflows, pinpointing areas with weak or insufficient methodologies <span class="citation" data-cites="barnettSevenFailurePoints2024">(<a href="#ref-barnettSevenFailurePoints2024" role="doc-biblioref">Barnett et al. 2024</a>)</span>. For example, by analyzing large datasets, RAG reveals under-explored techniques like low-resource quantized LLMs, offering efficiency and accuracy benefits overlooked in conventional dataset-building <span class="citation" data-cites="ranjanmaharanaRetrievalAugmentedGeneration2024">(<a href="#ref-ranjanmaharanaRetrievalAugmentedGeneration2024" role="doc-biblioref">Ranjan Maharana and Joshi 2024</a>)</span>. This capability allows surveying current methods and identifying areas lacking detailed research.</p>
<p>RAG application in benchmarking and comparative analysis exposes inconsistencies and under-researched areas. When used for evaluations, such as in multilingual medical question answering, RAG reveals performance drops in contexts like non-English languages, underscoring methodological blind spots or areas where methods lack robustness <span class="citation" data-cites="alonsoMedExpQAMultilingualBenchmarking2024">(<a href="#ref-alonsoMedExpQAMultilingualBenchmarking2024" role="doc-biblioref">Alonso, Oronoz, and Agerri 2024</a>)</span>. Highlighting performance discrepancies helps recognize variations in methodological effectiveness or under-defined methods, surfacing research gaps <span class="citation" data-cites="barnettSevenFailurePoints2024">(<a href="#ref-barnettSevenFailurePoints2024" role="doc-biblioref">Barnett et al. 2024</a>)</span>.</p>
<p>Insights from RAG application guide selecting and refining future research methodologies. RAG spotlights actionable improvements; for example, quantized LLMs reducing computational demand while improving accuracy suggests a methodological shift <span class="citation" data-cites="ranjanmaharanaRetrievalAugmentedGeneration2024">(<a href="#ref-ranjanmaharanaRetrievalAugmentedGeneration2024" role="doc-biblioref">Ranjan Maharana and Joshi 2024</a>)</span>. RAG systems also recommend analytical strategies, such as guiding target selection in drug design or suggesting techniques to overcome limitations in traditional methods, informing future research <span class="citation" data-cites="zhangBiSpecPairwiseAI2024 xuAutomatingBibliometricAnalysis2024">(<a href="#ref-zhangBiSpecPairwiseAI2024" role="doc-biblioref">Zhang, Wang, and Sun 2024</a>; <a href="#ref-xuAutomatingBibliometricAnalysis2024" role="doc-biblioref">H. Xu et al. 2024</a>)</span>.</p>
</section>
<section id="discussion" class="level2" data-number="13.7">
<h2 data-number="13.7" class="anchored" data-anchor-id="discussion"><span class="header-section-number">13.7</span> Discussion</h2>
<p>The development of this automated Extract, Transform, Load (ETL) and Retrieval-Augmented Generation (RAG) pipeline was undertaken as a direct response to the inherent challenges of identifying a novel and impactful research topic within a complex domain like geospatial epidemiology. As highlighted in our course’s “Advice on Research,” selecting a research problem carefully, focusing on fundamentals, and finding a unique perspective in potentially crowded areas are crucial early steps. This system was engineered to provide a systematic and efficient methodology for this discovery process, using the intersection of ozone exposure, heart disease, and geospatial/machine learning techniques as its initial proving ground.</p>
<p>The pipeline’s architecture is tailored to facilitate an iterative research discovery workflow, as outlined in the project’s data collection and integration strategy. The rapid ETL phase, capable of processing hundreds of articles in minutes using modules like fast_pubmed.py and GPU-accelerated Docling <span class="citation" data-cites="auerDoclingTechnicalReport2024">(<a href="#ref-auerDoclingTechnicalReport2024" role="doc-biblioref">Auer et al. 2024</a>)</span>, allows for an initial broad sweep of the literature. Subsequently, the integration of Latent Dirichlet Allocation (LDA) via topic_modeling_culda.py enables the automated categorization of this literature and, crucially, the identification of “weakly populated or contradictory clusters,” which serve as indicators of potential knowledge gaps or under-explored methodological niches. This aligns with the goal of finding less “crowded” research areas. The system then leverages these insights to refine search queries, allowing for a more targeted collection of literature to deepen understanding around these identified gaps. This iterative process of broad collection, gap identification via topic modeling and LLM interpretation, and refined collection is central to the system’s utility in topic formulation.</p>
<p>Furthermore, the RAG component, with its knowledge graph integration (Neo4j, kg_pipeline.py, inspired by <span class="citation" data-cites="tuMitigatingGrandChallenges2024">Tu et al. (<a href="#ref-tuMitigatingGrandChallenges2024" role="doc-biblioref">2024</a>)</span>) and novel Reciprocal-Rank Fusion (RRF) for precise retrieval, allows for nuanced exploration of these identified gaps. It enables users to query the enriched, gap-focused corpus to understand existing methodologies and pinpoint specific underrepresented geospatial or machine learning approaches. The high metadata similarity scores (Levenshtein &gt;0.90) and stringent QA processes aim to ensure that the insights derived are based on accurate data, supporting the selection of a research question that is both relevant and methodologically sound. The system’s current application to the literature on ozone exposure and heart disease, with the intent to link findings to CDC datasets, serves as a practical demonstration of how this pipeline can navigate from a broad area of interest to a specific, data-informed research question, thereby operationalizing the principles of effective research topic selection. The pipeline doesn’t just automate literature review; it structures the exploratory phase of research itself.</p>
</section>
<section id="conclusion" class="level2" data-number="13.8">
<h2 data-number="13.8" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">13.8</span> Conclusion</h2>
<p>The primary contribution of this work is the development and practical demonstration of an automated ETL+RAG pipeline designed as a robust tool for systematically identifying research gaps and formulating novel research questions in complex scientific fields such as geospatial epidemiology. This system directly addresses the challenge of selecting a meaningful research topic by providing an efficient, scalable, and transparent framework for navigating and analyzing vast quantities of academic literature. By integrating rapid data ingestion, advanced PDF content extraction, iterative topic modeling for gap identification, and sophisticated RAG capabilities, the pipeline operationalizes key advice for effective research, enabling a structured approach to move from broad exploration to specific, actionable research directions.</p>
<p>The value of this pipeline lies in its capacity to empower researchers, particularly those embarking on new projects or exploring interdisciplinary areas, to efficiently discover under-explored methodological niches or substantive knowledge gaps. In the context of this project, it has laid the groundwork for pinpointing underrepresented geospatial and machine learning techniques in the study of ozone exposure and heart disease. More broadly, this process-oriented tool offers a significant advancement over traditional manual methods, demonstrating how AI can be leveraged not just for data analysis, but for the foundational stage of research discovery itself, fostering methodologically sound and impactful inquiry.</p>
</section>
<section id="future-directions" class="level2" data-number="13.9">
<h2 data-number="13.9" class="anchored" data-anchor-id="future-directions"><span class="header-section-number">13.9</span> Future Directions</h2>
<p>Future development of this ETL+RAG pipeline will focus on enhancing its efficacy as a research discovery tool and broadening its application. A key priority is the refinement of the quality assurance (QA) process to reduce the “occasional false negatives” and improve the precision of gap identification. This involves exploring more dynamic error detection and advanced hallucination mitigation strategies for the LLM components <span class="citation" data-cites="huangSurveyHallucinationLarge2024 fanSurveyRAGMeeting2024">(<a href="#ref-huangSurveyHallucinationLarge2024" role="doc-biblioref">Huang et al. 2024</a>; <a href="#ref-fanSurveyRAGMeeting2024" role="doc-biblioref">Fan et al. 2024</a>)</span>.</p>
<p>From a research process perspective, the immediate next step involves applying the methodologies identified by the pipeline to the large-scale CDC datasets on ozone and heart disease. This will involve implementing relevant machine learning approaches (e.g., Random Forest, geospatial cross-validation) to analyze these datasets, thereby empirically validating the research gap identified by the pipeline and completing the class project’s analytical component. The insights from this application will also serve as a feedback loop for further refining the pipeline’s gap identification capabilities.</p>
<p>Further enhancements to the pipeline itself will include exploring computational efficiencies, such as the integration of quantized LLMs <span class="citation" data-cites="ranjanmaharanaRetrievalAugmentedGeneration2024">(<a href="#ref-ranjanmaharanaRetrievalAugmentedGeneration2024" role="doc-biblioref">Ranjan Maharana and Joshi 2024</a>)</span> and optimized retrieval mechanisms <span class="citation" data-cites="wangSearchingBestPractices2024">(<a href="#ref-wangSearchingBestPractices2024" role="doc-biblioref">Wang et al. 2024</a>)</span>, to manage costs and improve processing speeds for even larger literature corpora. Incorporating more sophisticated uncertainty-aware retrieval <span class="citation" data-cites="dholeRetrieveNotRetrieve2025">(<a href="#ref-dholeRetrieveNotRetrieve2025" role="doc-biblioref">Dhole 2025</a>)</span> and explicit bias detection mechanisms <span class="citation" data-cites="liAugmentingLargeLanguage2024">(<a href="#ref-liAugmentingLargeLanguage2024" role="doc-biblioref">Li and Lai 2024</a>)</span> will also be critical. Finally, the modular design of the pipeline lends itself to expansion. Future work will aim to test its generalizability by applying it to identify methodological gaps in other epidemiological areas and diverse scientific domains, potentially fine-tuning domain-specific LLMs to enhance its utility for a wider range of research discovery tasks.</p>
<hr>
</section>
</section>
<section id="data-management" class="level1" data-number="14">
<h1 data-number="14"><span class="header-section-number">14</span> Data Management</h1>
<p>This dissertation will integrate three distinct categories of data, each corresponding to a specific research aim.</p>
<section id="scholarly-literature-corpus-for-aim-1" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="scholarly-literature-corpus-for-aim-1"><span class="header-section-number">14.1</span> Scholarly Literature Corpus (for Aim 1)</h2>
<ul>
<li><strong>Sources:</strong> PubMed, OpenAlex, and Scopus for article metadata; Unpaywall and publisher websites for full-text PDFs.</li>
<li><strong>Volume:</strong> An initial corpus of up to 1,000 PDF articles, with the system designed to scale to several thousand.</li>
<li><strong>Formats:</strong> Source metadata (JSON), extracted article content (Markdown), structured data (Feather files), and semantic embeddings stored in a Qdrant vector database.</li>
</ul>
</section>
<section id="public-health-and-environmental-datasets-for-aim-2" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="public-health-and-environmental-datasets-for-aim-2"><span class="header-section-number">14.2</span> Public Health and Environmental Datasets (for Aim 2)</h2>
<ul>
<li><strong>Sources:</strong> U.S. Centers for Disease Control and Prevention (CDC) Wonder and Data.gov portals.</li>
<li><strong>Specific Datasets:</strong> Daily census-tract level ozone concentrations (2001-2014); county-level cardiovascular disease mortality rates (2000-2019); and U.S. Census data for demographic covariates.</li>
<li><strong>Volume:</strong> Tens of gigabytes, comprising over 400 million row-level observations in the source files.</li>
<li><strong>Formats:</strong> CSV files, which will be processed and stored in the efficient Feather format for analysis.</li>
</ul>
</section>
<section id="geospatial-and-remote-sensing-imagery-for-aim-3" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="geospatial-and-remote-sensing-imagery-for-aim-3"><span class="header-section-number">14.3</span> Geospatial and Remote Sensing Imagery (for Aim 3)</h2>
<ul>
<li><strong>Sources:</strong> Public and commercial satellite data providers.
<ul>
<li><strong>Optical Imagery:</strong> High-resolution (0.5m - 2m) multi-spectral imagery from sources such as the National Agriculture Imagery Program (NAIP), Planet, or Maxar.</li>
<li><strong>Methane Data:</strong> High-resolution methane concentration data from emerging platforms like MethaneSAT, Carbon Mapper, and GHGSat.</li>
<li><strong>Contextual Data:</strong> Geocoded tax parcel data from county governments and LULC data from the USGS.</li>
</ul></li>
<li><strong>Volume:</strong> Terabytes of raster and vector data covering large geographical areas of interest.</li>
<li><strong>Formats:</strong> GeoTIFF (for raster imagery), Shapefile or GeoJSON (for vector data), and CSVs.</li>
</ul>
<hr>
</section>
</section>
<section id="expected-results" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> Expected Results</h1>
<p>The successful completion of this dissertation will yield four primary outcomes, with each of the first three corresponding directly to a specific research aim.</p>
<section id="a-novel-ai-powered-literature-analysis-pipeline-from-aim-1" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="a-novel-ai-powered-literature-analysis-pipeline-from-aim-1"><span class="header-section-number">15.1</span> A Novel AI-Powered Literature Analysis Pipeline (from Aim 1)</h2>
<ul>
<li>A complete, open-source Python-based ETL and RAG pipeline that enables the seamless, automated ingestion, extraction, and analysis of scientific literature to systematically identify methodological research gaps.</li>
</ul>
</section>
<section id="a-baseline-model-of-ozones-impact-on-cardiovascular-health-from-aim-2" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="a-baseline-model-of-ozones-impact-on-cardiovascular-health-from-aim-2"><span class="header-section-number">15.2</span> A Baseline Model of Ozone’s Impact on Cardiovascular Health (from Aim 2)</h2>
<ul>
<li>A robust machine learning analysis quantifying the association between various ozone exposure metrics and county-level CVD mortality in the U.S. This will serve as a critical baseline and a direct application of the gap-finding pipeline.</li>
</ul>
</section>
<section id="a-state-of-the-art-framework-and-inventory-for-uog-monitoring-from-aim-3" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="a-state-of-the-art-framework-and-inventory-for-uog-monitoring-from-aim-3"><span class="header-section-number">15.3</span> A State-of-the-Art Framework and Inventory for UOG Monitoring (from Aim 3)</h2>
<ul>
<li>A validated deep learning framework (CNN/GNN) capable of identifying and classifying the activity status of UOG sites at scale using multi-modal satellite data. The primary deliverable will be a novel, high-resolution spatiotemporal inventory of UOG wells, providing a foundational dataset for future environmental health research.</li>
</ul>
</section>
<section id="comprehensive-documentation-and-dissemination" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="comprehensive-documentation-and-dissemination"><span class="header-section-number">15.4</span> Comprehensive Documentation and Dissemination</h2>
<ul>
<li>A final dissertation document and an interactive Quarto-based report demonstrating the literature-derived insights, the baseline geospatial analysis, and the innovative deep learning framework and its outputs.</li>
</ul>
<hr>
</section>
</section>
<section id="example-data-extraction-functions" class="level1" data-number="16">
<h1 data-number="16"><span class="header-section-number">16</span> Example data extraction functions</h1>
<p>In this section, I provide sample code snippets that I’ve developed for the ETL pipeline. Each function targets a specific stage: PubMed metadata fetching, PDF retrieval from Unpaywall, Docling-based text extraction, Zotero integration, etc.</p>
<section id="module-fast_pubmed.py" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="module-fast_pubmed.py"><span class="header-section-number">16.1</span> Module: <code>fast_pubmed.py</code></h2>
<p><strong>Description:</strong><br>
A drop-in turbo-replacement for the two original helpers:</p>
<ul>
<li><code>pubmed_search_chunked</code></li>
<li><code>fetch_pubmed_metadata</code></li>
</ul>
<p><strong>Key features:</strong> - &lt; 1 s single <code>esearch</code> to collect up-to-10,000 PMIDs. - Thread-pooled, rate-limited bulk-<code>efetch</code> (≤ 3 req/s/IP – NCBI TOS). - Parses the same rich metadata as previously used: Authors, Date, Journal, Volume, Issue, Pages, plus Title / DOI / Abstract. - Robust logging with granular exception capture; a bad article never aborts the batch. - No hard-wired globals; everything is configurable via keyword args.</p>
</section>
<section id="module-fast_openalex.py" class="level2" data-number="16.2">
<h2 data-number="16.2" class="anchored" data-anchor-id="module-fast_openalex.py"><span class="header-section-number">16.2</span> Module: <code>fast_openalex.py</code></h2>
<p><strong>Description:</strong><br>
A Python module for rapidly querying and retrieving scholarly records from the OpenAlex API, designed to complement PubMed searches by capturing literature not indexed in PubMed. Utilizing asynchronous I/O and parallel processing, this tool fetches article metadata at scale, parsing and formatting results into a convenient DataFrame for immediate integration into the analysis pipeline.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>High-Speed Retrieval:</strong> Uses asynchronous API requests (<code>aiohttp</code>) and concurrent fetching to maximize throughput while respecting rate limits.</li>
<li><strong>Efficient Pagination:</strong> Automatically handles pagination and cursor-based retrieval, fetching results swiftly and transparently.</li>
<li><strong>Robust Parsing and Cleaning:</strong> Extracts and cleans metadata such as DOI, abstracts, authorship, publication dates, journal information, and page ranges, ensuring standardized, analysis-ready outputs.</li>
<li><strong>Easy Integration:</strong> Provides a simple wrapper (<code>search_works_df</code>) that returns results in a Pandas DataFrame consistent with existing data processing workflows.</li>
<li><strong>Polite API Interaction:</strong> Adheres strictly to recommended OpenAlex rate limits, ensuring reliable, long-term API access without throttling.</li>
<li><strong>Configurable &amp; Flexible:</strong> Easily adjustable query parameters, such as items per page, concurrency level, and query-per-second rate, allow for custom optimizations.</li>
</ul>
<p>Ideal for comprehensive literature reviews, systematic analyses, and dataset augmentation tasks that require accessing a broader scope of scholarly publications beyond traditional indexing services like PubMed.</p>
</section>
<section id="module-etl_elsevier.py" class="level2" data-number="16.3">
<h2 data-number="16.3" class="anchored" data-anchor-id="module-etl_elsevier.py"><span class="header-section-number">16.3</span> Module: <code>etl_elsevier.py</code></h2>
<p><strong>Description:</strong><br>
A Python module for retrieving scholarly articles from Elsevier’s Scopus database, integrating with the existing ETL workflow. It uses asynchronous requests (aiohttp) to fetch article metadata, enriches records via Crossref, and handles data parsing, error management, and structured data outputs.</p>
<p><strong>Main Functionalities:</strong></p>
<p>The module retrieves metadata from Scopus using paginated requests while adhering to Elsevier’s API rate limits and parsing key metadata such as DOI, Scopus ID, titles, and journal information. It concurrently enriches this data with additional details from Crossref, including authors, abstracts, and PDF links, incorporating error handling, retries, and standardized field formatting. Configuration settings—including API credentials, endpoints, rate limits, concurrency, and logging—are managed externally via a JSON file (<code>etl_config.json</code>), which supports flexible adjustments and provides detailed logging for error tracking. The final enriched metadata is structured into Pandas DataFrames with standardized columns optimized for downstream ETL workflows.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Asynchronous Requests:</strong> Utilizes asyncio/aiohttp for scalable, concurrent API requests, improving throughput.</li>
<li><strong>Flexible Configuration:</strong> All configurations (API keys, search parameters, file paths) managed via external JSON for flexibility.</li>
<li><strong>Robust Parsing &amp; Data Integrity:</strong> Implements metadata parsing with safeguards to maintain data quality.</li>
<li><strong>Comprehensive Logging:</strong> Detailed logging provides real-time insights into data fetching, processing status, and error handling.</li>
</ul>
<p>Ideal for comprehensive literature reviews, systematic analyses, and dataset augmentation tasks that require accessing a broader scope of scholarly publications beyond traditional indexing services like PubMed.</p>
</section>
<section id="module-async_unpaywall.py" class="level2" data-number="16.4">
<h2 data-number="16.4" class="anchored" data-anchor-id="module-async_unpaywall.py"><span class="header-section-number">16.4</span> Module: <code>async_unpaywall.py</code></h2>
<p><strong>Description:</strong><br>
A helper function for quickly retrieving full-text PDFs from the Unpaywall API given DOI identifiers. Ideal for automated bulk PDF downloads in an ETL workflow.</p>
<p><strong>Key features:</strong></p>
<ul>
<li>Uses Python’s asynchronous libraries (<code>asyncio</code> + <code>aiohttp</code>) for concurrent fetching.</li>
<li>Adheres to Unpaywall’s API limits (≤ 8 requests per second).</li>
<li>Supports optional proxy rotation for reliability.</li>
<li>Automatically sanitizes PDF filenames, preventing file-system errors.</li>
<li>handles HTTP failures, missing PDFs, and other edge cases with logging.</li>
</ul>
</section>
<section id="module-docling_extract_formulas_mp_multi.py" class="level2" data-number="16.5">
<h2 data-number="16.5" class="anchored" data-anchor-id="module-docling_extract_formulas_mp_multi.py"><span class="header-section-number">16.5</span> Module <code>docling_extract_formulas_mp_multi.py</code></h2>
<p><strong>Description:</strong><br>
A multiprocessing-optimized PDF extraction module using Docling’s layout analysis capabilities, enriched with GPU acceleration. It converts PDFs into structured text, accurately extracting elements such as tables, equations, and formatted text.</p>
<p><strong>Key features:</strong></p>
<ul>
<li>Multi-process parallelization with GPU allocation for optimized throughput.</li>
<li>Extracts full document text as Markdown, handling complex formatting and special characters.</li>
<li>Specialized extraction for embedded LaTeX formulas and structured table data.</li>
<li>error handling and logging ensure resilience against problematic PDFs.</li>
<li>Integrated token-counting for downstream NLP workflows.</li>
</ul>
</section>
<section id="module-fast_zotero.py" class="level2" data-number="16.6">
<h2 data-number="16.6" class="anchored" data-anchor-id="module-fast_zotero.py"><span class="header-section-number">16.6</span> Module: <code>fast_zotero.py</code></h2>
<p><strong>Description:</strong><br>
A helper module designed forintegration with Zotero citation management workflows. Enables batch creation of Zotero items, parallelized PDF uploads, and automatic citation formatting via local <code>citeproc</code> rendering.</p>
<p><strong>Key features:</strong></p>
<ul>
<li>batch creation of Zotero items (up to 50 items per API call).</li>
<li>Parallelized PDF attachment uploads via thread pooling.</li>
<li>Local citation rendering using the CSL (<code>citeproc</code>) engine for instant citation generation without API latency.</li>
<li>Optional fallback to Zotero’s built-in citation rendering API if local citation rendering encounters issues.</li>
<li>customizable citation-style handling through a configurable local CSL style registry.</li>
</ul>
</section>
<section id="module-field_extraction.py" class="level2" data-number="16.7">
<h2 data-number="16.7" class="anchored" data-anchor-id="module-field_extraction.py"><span class="header-section-number">16.7</span> Module: <code>field_extraction.py</code></h2>
<p><strong>Description:</strong><br>
A extraction module that enhances a Feather-format DataFrame by retrieving structured metadata fields through iterative Large Language Model (LLM) calls. It uses techniques for JSON parsing, LLM response caching, tokenization, parallelized processing, and merging strategies to maintain data integrity and avoid duplication.</p>
<p><strong>Key features:</strong></p>
<ul>
<li><strong>Robust JSON Parsing:</strong> Cleans and interprets LLM-generated JSON output, handling common formatting errors.</li>
<li><strong>Intelligent LLM Caching:</strong> Avoids redundant API calls by caching LLM responses based on prompt content hashes.</li>
<li><strong>Parallel Processing:</strong> Employs thread pools for efficient concurrent handling of multiple data rows and text chunks.</li>
<li><strong>Dynamic Text Chunking:</strong> Splits long texts into manageable segments to stay within LLM token limits, ensuring comprehensive extraction.</li>
<li><strong>Field Unification:</strong> Carefully merges newly extracted data with existing metadata, ensuring consistency and preventing duplication, especially within structured fields such as numeric metrics.</li>
<li><strong>Comprehensive Logging:</strong> Detailed logging and exception handling provide transparency and facilitate troubleshooting.</li>
</ul>
<p>This module is particularly optimized for workflows involving complex metadata extraction scenarios, such as academic literature reviews, where accuracy, scalability, and structured data consistency are crucial.</p>
</section>
<section id="module-topic_modeling_gui.py" class="level2" data-number="16.8">
<h2 data-number="16.8" class="anchored" data-anchor-id="module-topic_modeling_gui.py"><span class="header-section-number">16.8</span> Module: <code>topic_modeling_gui.py</code></h2>
<p><strong>Description:</strong><br>
A Python module for performing topic modeling on large document collections using parallelized workflows. It combines text preprocessing with Latent Dirichlet Allocation (LDA) modeling, supporting both scikit-learn and Gensim frameworks. The module emphasizes computational efficiency through parallel processing, optimized BLAS thread usage, and structured hyperparameter searches to achieve the highest-quality topic coherence.</p>
<p><strong>Key features:</strong></p>
<ul>
<li><strong>Robust Preprocessing:</strong> Efficiently cleans text by removing references, standardizing formats, tokenizing, removing stopwords, and lemmatizing.</li>
<li><strong>Parallel Processing:</strong> Utilizes multiprocessing and threading for rapid tokenization, preprocessing, and dominant-topic extraction, significantly speeding up operations on large datasets.</li>
<li><strong>Flexible LDA Implementation:</strong> integrates scikit-learn’s LDA models with fallback support for Gensim models, ensuring consistent performance and reliability.</li>
<li><strong>Hyperparameter Optimization:</strong> Uses exhaustive grid search across critical LDA parameters (e.g., number of topics, bigram/trigram thresholds), optimizing for coherence scores.</li>
<li><strong>Dominant Topic Identification:</strong> Efficiently extracts and summarizes the most significant topics per document, indicating their contribution and top keywords.</li>
<li><strong>Detailed Logging and Error Handling:</strong> Provides logging at each processing step, simplifying debugging and ensuring transparency of the modeling process.</li>
</ul>
<p>Ideal for research-intensive tasks such as systematic literature reviews, thematic content analysis, or exploratory text analysis, this module enhances productivity and result quality through its structured approach.</p>
</section>
<section id="module-kg_pipeline.py" class="level2" data-number="16.9">
<h2 data-number="16.9" class="anchored" data-anchor-id="module-kg_pipeline.py"><span class="header-section-number">16.9</span> Module: <code>kg_pipeline.py</code></h2>
<p><strong>Description:</strong><br>
The <code>kg_pipeline.py</code> script serves as a integration module that transforms structured article metadata and analytical results into a Knowledge Graph (KG) within a Neo4j database. It handles entity and relationship management, ensures data integrity via constraints, and uses unified terminology dictionaries for consistent entity naming.</p>
<p><strong>Main functionalities include:</strong></p>
<ul>
<li><strong>Neo4j Integration</strong>:
<ul>
<li>Establishes connection and handles transactional updates to Neo4j.</li>
<li>Uses merge operations to add/update entities such as Articles, Study Types, Soil Types, Cover Crops, and more.</li>
</ul></li>
<li><strong>Entity Unification</strong>:
<ul>
<li>Applies extensive synonym unification via <code>dictionaries.py</code> to standardize terminology across various fields, ensuring consistency and accuracy in the knowledge graph.</li>
</ul></li>
<li><strong>Dynamic Schema Management</strong>:
<ul>
<li>Automatically sets up Neo4j constraints to maintain schema integrity and database performance.</li>
</ul></li>
<li><strong>Error Handling &amp; Logging</strong>:
<ul>
<li>Comprehensive logging and exception handling facilitate easy debugging and robust data integrity verification during the KG construction process.</li>
</ul></li>
<li><strong>Integration with Topic Modeling</strong>:
<ul>
<li>Incorporates dominant topics and associated metadata, linking textual analysis results directly within the KG.</li>
</ul></li>
</ul>
</section>
<section id="module-dictionaries.py" class="level2" data-number="16.10">
<h2 data-number="16.10" class="anchored" data-anchor-id="module-dictionaries.py"><span class="header-section-number">16.10</span> Module: <code>dictionaries.py</code></h2>
<p><strong>Description:</strong><br>
This module contains dictionaries used for unifying terminology across numerous categories in the ETL pipeline. With thousands of terms and synonyms across 30+ dictionaries, it supports consistency and accuracy of entity representation within the knowledge graph.</p>
<p><strong>Key Dictionaries Include</strong>: - <strong>Study Types</strong> - <strong>Environmental Impact Categories</strong> - <strong>Management Practices</strong> - <strong>Cover Crops</strong> - <strong>Tillage Practices</strong> - <strong>Metric Names</strong> - <strong>Machine Learning Methods</strong> - and many more.</p>
<p>These unified dictionaries provide synonym resolution capabilities to handle variations in terminology commonly encountered across scientific literature.</p>
<hr>
</section>
</section>
<section id="references" class="level1" data-number="17">
<h1 data-number="17"><span class="header-section-number">17</span> References</h1>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aditya_understanding_2024" class="csl-entry" role="listitem">
Aditya, G. 2024. <span>“Understanding and <span>Addressing</span> <span>AI</span> <span>Hallucinations</span> in <span>Healthcare</span> and <span>Life</span> <span>Sciences</span>.”</span> <em>International Journal of Health Sciences</em> 7 (3): 1–11. <a href="https://doi.org/10.47941/ijhs.1862">https://doi.org/10.47941/ijhs.1862</a>.
</div>
<div id="ref-alghadbanTransformingHealthcareEducation2023" class="csl-entry" role="listitem">
Al Ghadban, Yasmina, Huiqi Lu, Uday Adavi, Ankita Sharma, Sridevi Gara, Neelanjana Das, B. R. Kumar, Renu John, Devarsetty Praveen, and Jane E. Hirst. 2023. <span>“Transforming <span>Healthcare Education</span>: <span>Harnessing Large Language Models</span> for <span>Frontline Health Worker Capacity Building</span> Using <span>Retrieval-Augmented Generation</span>.”</span> <em>medRxiv (Cold Spring Harbor Laboratory)</em>, December. <a href="https://doi.org/10.1101/2023.12.15.23300009">https://doi.org/10.1101/2023.12.15.23300009</a>.
</div>
<div id="ref-alonsoMedExpQAMultilingualBenchmarking2024" class="csl-entry" role="listitem">
Alonso, Iñigo, Maite Oronoz, and Rodrigo Agerri. 2024. <span>“<span>MedExpQA</span>: <span>Multilingual</span> Benchmarking of <span>Large Language Models</span> for <span>Medical Question Answering</span>.”</span> <em>Artificial Intelligence in Medicine</em> 155 (July): 102938–38. <a href="https://doi.org/10.1016/j.artmed.2024.102938">https://doi.org/10.1016/j.artmed.2024.102938</a>.
</div>
<div id="ref-auerDoclingTechnicalReport2024" class="csl-entry" role="listitem">
Auer, Christoph, Maksym Lysak, Ahmed Nassar, Michele Dolfi, Nikolaos Livathinos, Panos Vagenas, Cesar Berrospi Ramis, et al. 2024. <span>“Docling <span>Technical Report</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2408.09869">https://doi.org/10.48550/arXiv.2408.09869</a>.
</div>
<div id="ref-barnettSevenFailurePoints2024" class="csl-entry" role="listitem">
Barnett, Scott, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, and Mohamed Abdelrazek. 2024. <span>“Seven <span>Failure Points When Engineering</span> a <span>Retrieval Augmented Generation System</span>,”</span> April. <a href="https://doi.org/10.1145/3644815.3644945">https://doi.org/10.1145/3644815.3644945</a>.
</div>
<div id="ref-dernbach_glam_2024" class="csl-entry" role="listitem">
Dernbach, Stefan, Khushbu Agarwal, Alejandro Zuniga, Michael Henry, and Sutanay Choudhury. 2024. <span>“<span>GLaM</span>: <span>Fine</span>-<span>Tuning</span> <span>Large</span> <span>Language</span> <span>Models</span> for <span>Domain</span> <span>Knowledge</span> <span>Graph</span> <span>Alignment</span> via <span>Neighborhood</span> <span>Partitioning</span> and <span>Generative</span> <span>Subgraph</span> <span>Encoding</span>.”</span> <em>Proceedings of the AAAI Symposium Series</em> 3 (1): 82–89. <a href="https://doi.org/10.1609/aaaiss.v3i1.31186">https://doi.org/10.1609/aaaiss.v3i1.31186</a>.
</div>
<div id="ref-dholeRetrieveNotRetrieve2025" class="csl-entry" role="listitem">
Dhole, Kaustubh D. 2025. <span>“To <span>Retrieve</span> or <span>Not</span> to <span>Retrieve</span>? <span>Uncertainty Detection</span> for <span>Dynamic Retrieval Augmented Generation</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2501.09292">https://doi.org/10.48550/arXiv.2501.09292</a>.
</div>
<div id="ref-di_maria_netme_2024" class="csl-entry" role="listitem">
Di Maria, Antonio, Lorenzo Bellomo, Fabrizio Billeci, Alfio Cardillo, Salvatore Alaimo, Paolo Ferragina, Alfredo Ferro, and Alfredo Pulvirenti. 2024. <span>“<span>NetMe</span> 2.0: A Web-Based Platform for Extracting and Modeling Knowledge from Biomedical Literature as a Labeled Graph.”</span> <em>Bioinformatics</em> 40 (5). <a href="https://doi.org/10.1093/bioinformatics/btae194">https://doi.org/10.1093/bioinformatics/btae194</a>.
</div>
<div id="ref-fanSurveyRAGMeeting2024" class="csl-entry" role="listitem">
Fan, Wenqi, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. 2024. <span>“A <span>Survey</span> on <span>RAG Meeting LLMs</span>: <span>Towards Retrieval-Augmented Large Language Models</span>.”</span> <em>Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, August, 6491–501. <a href="https://doi.org/10.1145/3637528.3671470">https://doi.org/10.1145/3637528.3671470</a>.
</div>
<div id="ref-fatehaliAutomatedLiteratureReview2024" class="csl-entry" role="listitem">
Fateh Ali, Nurshat, Md. Mahdi Mohtasim, Shakil Mosharrof, and T. Gopi Krishna. 2024. <span>“Automated <span>Literature Review Using NLP Techniques</span> and <span>LLM-Based Retrieval-Augmented Generation</span>.”</span> <em>2022 International Conference on Innovations in Science, Engineering and Technology (ICISET)</em>, October, 1–6. <a href="https://doi.org/10.1109/iciset62123.2024.10939517">https://doi.org/10.1109/iciset62123.2024.10939517</a>.
</div>
<div id="ref-fengRetrievalGenerationSynergyAugmented2024" class="csl-entry" role="listitem">
Feng, Zhangyin, Xiaocheng Feng, Dezhi Zhao, Maojin Yang, and Bing Qin. 2024. <span>“Retrieval-<span>Generation Synergy Augmented Large Language Models</span>.”</span> <em>ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, March, 11661–65. <a href="https://doi.org/10.1109/icassp48485.2024.10448015">https://doi.org/10.1109/icassp48485.2024.10448015</a>.
</div>
<div id="ref-fleurenceGenerativeAIHealth2024a" class="csl-entry" role="listitem">
Fleurence, Rachael, Jiang Bian, Xiaoyan Wang, Hua Xu, Dalia Dawoud, Mitch Higashi, and Jagpreet Chhatwal. 2024b. <span>“Generative <span>AI</span> for <span>Health Technology Assessment</span>: <span>Opportunities</span>, <span>Challenges</span>, and <span>Policy Considerations</span> - an <span>ISPOR Working Group Report</span>.”</span> <em>Value in Health</em>, November. <a href="https://doi.org/10.1016/j.jval.2024.10.3846">https://doi.org/10.1016/j.jval.2024.10.3846</a>.
</div>
<div id="ref-fleurence_generative_2024" class="csl-entry" role="listitem">
———. 2024a. <span>“Generative <span>AI</span> for <span>Health</span> <span>Technology</span> <span>Assessment</span>: <span>Opportunities</span>, <span>Challenges</span>, and <span>Policy</span> <span>Considerations</span> - an <span>ISPOR</span> <span>Working</span> <span>Group</span> <span>Report</span>.”</span> <em>Value in Health</em>, November. <a href="https://doi.org/10.1016/j.jval.2024.10.3846">https://doi.org/10.1016/j.jval.2024.10.3846</a>.
</div>
<div id="ref-gangemi_logic_2025" class="csl-entry" role="listitem">
Gangemi, Aldo, and Andrea Giovanni Nuzzolese. 2025. <span>“Logic Augmented Generation.”</span> <em>Journal of Web Semantics</em>, January, 100859–59. <a href="https://doi.org/10.1016/j.websem.2024.100859">https://doi.org/10.1016/j.websem.2024.100859</a>.
</div>
<div id="ref-guProbabilisticMedicalPredictions2024" class="csl-entry" role="listitem">
Gu, Bowen, Rishi Desai, Kueiyu Joshua Lin, and Jie Yang. 2024. <span>“Probabilistic Medical Predictions of Large Language Models.”</span> <em>Npj Digital Medicine</em> 7 (1). <a href="https://doi.org/10.1038/s41746-024-01366-4">https://doi.org/10.1038/s41746-024-01366-4</a>.
</div>
<div id="ref-gue_evaluating_2024" class="csl-entry" role="listitem">
Gue, Celeste Ci Ying, Noorul Dharajath Abdul Rahim, William Rojas-Carabali, Rupesh Agrawal, Palvannan Rk, John Abisheganaden, and Wan Fen Yip. 2024. <span>“Evaluating the <span>OpenAI</span>’s <span>GPT</span>-3.5 <span>Turbo</span>’s Performance in Extracting Information from Scientific Articles on Diabetic Retinopathy.”</span> <em>Systematic Reviews</em> 13 (1): 135. <a href="https://doi.org/10.1186/s13643-024-02523-2">https://doi.org/10.1186/s13643-024-02523-2</a>.
</div>
<div id="ref-huangSurveyHallucinationLarge2024" class="csl-entry" role="listitem">
Huang, Lei, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, et al. 2024. <span>“A <span>Survey</span> on <span>Hallucination</span> in <span>Large Language Models</span>: <span>Principles</span>, <span>Taxonomy</span>, <span>Challenges</span>, and <span>Open Questions</span>.”</span> <em>ACM Transactions on Office Information Systems</em>, November. <a href="https://doi.org/10.1145/3703155">https://doi.org/10.1145/3703155</a>.
</div>
<div id="ref-j_bolanos_artificial_2024" class="csl-entry" role="listitem">
J. Bolaños, F., Angelo A. Salatino, Francesco Osborne, and Enrico Motta. 2024. <span>“Artificial Intelligence for Literature Reviews: Opportunities and Challenges.”</span> <em>Artificial Intelligence Review</em> 57 (10). <a href="https://doi.org/10.1007/s10462-024-10902-3">https://doi.org/10.1007/s10462-024-10902-3</a>.
</div>
<div id="ref-kreimeyerUsingRetrievalAugmentedGeneration2024" class="csl-entry" role="listitem">
Kreimeyer, Kory, Jenna VanLiere Canzoniero, Maria Fatteh, Valsamo Anagnostou, and Taxiarchis Botsis. 2024. <span>“Using <span>Retrieval-Augmented Generation</span> to <span>Capture Molecularly-Driven Treatment Relationships</span> for <span>Precision Oncology</span>.”</span> <em>Studies in Health Technology and Informatics</em>, August. <a href="https://doi.org/10.3233/shti240575">https://doi.org/10.3233/shti240575</a>.
</div>
<div id="ref-lee_bring_2024" class="csl-entry" role="listitem">
Lee, Ha-rin, and Seohyun Kim. 2024. <span>“Bring <span>Retrieval</span> <span>Augmented</span> <span>Generation</span> to <span>Google</span> <span>Gemini</span> via <span>External</span> <span>API</span>: <span>An</span> <span>Evaluation</span> with <span>BIG</span>-<span>Bench</span> <span>Dataset</span>.”</span> <em>Research Square (Research Square)</em>, May. <a href="https://doi.org/10.21203/rs.3.rs-4394715/v1">https://doi.org/10.21203/rs.3.rs-4394715/v1</a>.
</div>
<div id="ref-liAugmentingLargeLanguage2024" class="csl-entry" role="listitem">
Li, Po-hao, and Ya-yun Lai. 2024. <span>“Augmenting <span>Large Language Models</span> with <span>Reverse Proxy Style Retrieval Augmented Generation</span> for <span>Higher Factual Accuracy</span>,”</span> May. <a href="https://doi.org/10.31219/osf.io/ma6cq">https://doi.org/10.31219/osf.io/ma6cq</a>.
</div>
<div id="ref-luu_bioinspiredllm_2023" class="csl-entry" role="listitem">
Luu, Rachel K, and Markus J Buehler. 2023. <span>“<span>BioinspiredLLM</span>: <span>Conversational</span> <span>Large</span> <span>Language</span> <span>Model</span> for the <span>Mechanics</span> of <span>Biological</span> and <span>Bio</span>-<span>Inspired</span> <span>Materials</span>.”</span> <em>Advanced Science (Weinheim, Baden-Wurttemberg, Germany)</em> 11 (10): e2306724. <a href="https://doi.org/10.1002/advs.202306724">https://doi.org/10.1002/advs.202306724</a>.
</div>
<div id="ref-ranjanmaharanaRetrievalAugmentedGeneration2024" class="csl-entry" role="listitem">
Ranjan Maharana, Piyush, and Kavita Joshi. 2024. <span>“Retrieval Augmented Generation for Building Datasets from Scientific Literature,”</span> November. <a href="https://doi.org/10.26434/chemrxiv-2024-qjx32">https://doi.org/10.26434/chemrxiv-2024-qjx32</a>.
</div>
<div id="ref-rawsonNgaAraWhakamana2024" class="csl-entry" role="listitem">
Rawson, Zane. 2024. <span>“The <span>Ng<span>ā</span> Ara Whakamana Process</span>: <span>Conceptualising</span> and <span>Designing</span> a <span>Process</span> to <span>Engage</span> with <span class="nocase">M<span class="nocase">ā</span>ori Trust Factors</span> in the <span>Development</span> of <span>IT Artefacts</span>,”</span> December. <a href="https://doi.org/10.26686/wgtn.28028579">https://doi.org/10.26686/wgtn.28028579</a>.
</div>
<div id="ref-sakarMaximizingRAGEfficiency2024" class="csl-entry" role="listitem">
Şakar, Tolga, and Hakan Emekci. 2024. <span>“Maximizing <span>RAG</span> Efficiency: <span>A</span> Comparative Analysis of <span>RAG</span> Methods.”</span> <em>Natural Language Processing.</em>, October, 1–25. <a href="https://doi.org/10.1017/nlp.2024.53">https://doi.org/10.1017/nlp.2024.53</a>.
</div>
<div id="ref-shah-mohammadiUtilizingRAGGPT42024" class="csl-entry" role="listitem">
Shah-Mohammadi, Fatemeh, and Joseph Finkelstein. 2024. <span>“Utilizing <span>RAG</span> and <span>GPT-4</span> for <span>Extraction</span> of <span>Substance Use Information</span> from <span>Clinical Notes</span>.”</span> <em>Studies in Health Technology and Informatics</em> 321 (November): 94–98. <a href="https://doi.org/10.3233/SHTI241070">https://doi.org/10.3233/SHTI241070</a>.
</div>
<div id="ref-tozuka_application_2024" class="csl-entry" role="listitem">
Tozuka, Ryota, Hisashi Johno, Akitomo Amakawa, Junichi Sato, Manabu Muto, Shogo Seki, Atsushi Komaba, and Hiroshi Onishi. 2024. <span>“Application of <span>NotebookLM</span>, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging.”</span> <em>Japanese Journal of Radiology</em>, November. <a href="https://doi.org/10.1007/s11604-024-01705-1">https://doi.org/10.1007/s11604-024-01705-1</a>.
</div>
<div id="ref-tsai_comparative_2024" class="csl-entry" role="listitem">
Tsai, Hsiao-Ching, Yueh-Fen Huang, and Chih-Wei Kuo. 2024. <span>“Comparative <span>Analysis</span> of <span>Automatic</span> <span>Literature</span> <span>Review</span> <span>Using</span> <span>Mistral</span> <span>Large</span> <span>Language</span> <span>Model</span> and <span>Human</span> <span>Reviewers</span>.”</span> <em>Research Square (Research Square)</em>, March. <a href="https://doi.org/10.21203/rs.3.rs-4022248/v1">https://doi.org/10.21203/rs.3.rs-4022248/v1</a>.
</div>
<div id="ref-tuMitigatingGrandChallenges2024" class="csl-entry" role="listitem">
Tu, Qingshi, Jing Guo, Nan Li, Jianchuan Qi, and Ming Xu. 2024. <span>“Mitigating <span>Grand Challenges</span> in <span>Life Cycle Inventory Modeling</span> Through the <span>Applications</span> of <span>Large Language Models</span>.”</span> <em>Environmental Science &amp; Technology</em> 58 (44): 19595–603. <a href="https://doi.org/10.1021/acs.est.4c07634">https://doi.org/10.1021/acs.est.4c07634</a>.
</div>
<div id="ref-tupayachi_towards_2024" class="csl-entry" role="listitem">
Tupayachi, Jose, Haowen Xu, Olufemi A. Omitaomu, Mustafa Can Camur, Aliza Sharmin, and Xueping Li. 2024. <span>“Towards <span>Next</span>-<span>Generation</span> <span>Urban</span> <span>Decision</span> <span>Support</span> <span>Systems</span> Through <span>AI</span>-<span>Powered</span> <span>Construction</span> of <span>Scientific</span> <span>Ontology</span> <span>Using</span> <span>Large</span> <span>Language</span> <span>Models</span>—<span>A</span> <span>Case</span> in <span>Optimizing</span> <span>Intermodal</span> <span>Freight</span> <span>Transportation</span>.”</span> <em>Smart Cities</em> 7 (5): 2392–2421. <a href="https://doi.org/10.3390/smartcities7050094">https://doi.org/10.3390/smartcities7050094</a>.
</div>
<div id="ref-upadhyayEnhancingHealthInformation2025" class="csl-entry" role="listitem">
Upadhyay, Rishabh, and Marco Viviani. 2025. <span>“Enhancing <span>Health Information Retrieval</span> with <span>RAG</span> by Prioritizing Topical Relevance and Factual Accuracy.”</span> <em>Deleted Journal</em> 28 (1). <a href="https://doi.org/10.1007/s10791-025-09505-5">https://doi.org/10.1007/s10791-025-09505-5</a>.
</div>
<div id="ref-wangSearchingBestPractices2024" class="csl-entry" role="listitem">
Wang, Xiaohua, Zhenhua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo Xu, Tianyuan Shi, et al. 2024. <span>“Searching for <span>Best Practices</span> in <span>Retrieval-Augmented Generation</span>.”</span> <em>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, January, 17716–36. <a href="https://doi.org/10.18653/v1/2024.emnlp-main.981">https://doi.org/10.18653/v1/2024.emnlp-main.981</a>.
</div>
<div id="ref-xuAutomatingBibliometricAnalysis2024" class="csl-entry" role="listitem">
Xu, Haowen, Xueping Li, Jose Tupayachi, Jianming Lian, and Olufemi A. Omitaomu. 2024. <span>“Automating <span>Bibliometric Analysis</span> with <span>Sentence Transformers</span> and <span>Retrieval-Augmented Generation</span> (<span>RAG</span>): <span>A Pilot Study</span> in <span>Semantic</span> and <span>Contextual Search</span> for <span>Customized Literature Characterization</span> for <span>High-Impact Urban Research</span>,”</span> October, 43–49. <a href="https://doi.org/10.1145/3681780.3697252">https://doi.org/10.1145/3681780.3697252</a>.
</div>
<div id="ref-xuEvaluationIntegrationRetrievalaugmented2024" class="csl-entry" role="listitem">
Xu, Ruiyu, Ying Hong, Feifei Zhang, and Hongmei Xu. 2024. <span>“Evaluation of the Integration of Retrieval-Augmented Generation in Large Language Model for Breast Cancer Nursing Care Responses.”</span> <em>Scientific Reports</em> 14 (1): 30794. <a href="https://doi.org/10.1038/s41598-024-81052-3">https://doi.org/10.1038/s41598-024-81052-3</a>.
</div>
<div id="ref-yuan_leveraging_2024" class="csl-entry" role="listitem">
Yuan, Shuai, Fu Li, Matthew H. E. M. Browning, Mondira Bardhan, Kuiran Zhang, Olivia McAnirlin, Muhammad Mainuddin Patwary, and Aaron Reuben. 2024. <span>“Leveraging and Exercising Caution with <span>ChatGPT</span> and Other Generative Artificial Intelligence Tools in Environmental Psychology Research.”</span> <em>Frontiers in Psychology</em> 15 (April). <a href="https://doi.org/10.3389/fpsyg.2024.1295275">https://doi.org/10.3389/fpsyg.2024.1295275</a>.
</div>
<div id="ref-zhangBiSpecPairwiseAI2024" class="csl-entry" role="listitem">
Zhang, Xin, Huiyu Wang, and Chunyun Sun. 2024. <span>“<span>BiSpec Pairwise AI</span>: Guiding the Selection of Bispecific Antibody Target Combinations with Pairwise Learning and <span>GPT</span> Augmentation.”</span> <em>Journal of Cancer Research and Clinical Oncology</em> 150 (5): 237. <a href="https://doi.org/10.1007/s00432-024-05740-3">https://doi.org/10.1007/s00432-024-05740-3</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./02-data-collection.html" class="pagination-link" aria-label="Data Collection">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Data Collection</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Literature Analytics and Methodological Gap Analysis in Geospatial Epidemiology"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Alex Godinez"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> today</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>#01-proposal.qmd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>**Working Title**:  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>“AI-Powered ETL &amp; RAG System for Large-Scale Academic Literature Analytics and Methodological Gap Analysis in Geospatial Epidemiology”</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu"># Overall Goal</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>I aim to create and execute an end-to-end research program that will:</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>**Develop an AI-Powered Pipeline (Aim 1)**: Engineer an automated system combining Extract, Transform, Load (ETL) and Retrieval-Augmented Generation (RAG) to systematically analyze scientific literature and identify methodological research gaps.</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>**Conduct a Baseline Analysis (Aim 2)**: Apply established machine learning techniques (e.g., Random Forest) to a well-defined environmental health question (ozone and cardiovascular disease) informed by the pipeline's findings.</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>**Innovate with Advanced Deep Learning (Aim 3)**: Address a key identified gap by developing and validating a novel deep learning framework (CNNs and GNNs) to tackle a challenging, high-impact problem—the large-scale identification and activity monitoring of unconventional oil and gas (UOG) development sites using satellite data.</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>The core objective is to demonstrate a complete research lifecycle: from AI-driven gap identification to baseline analysis, and culminating in the application of cutting-edge methods to create a new, foundational dataset for environmental health research. </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="fu"># Specific Aims and Research Questions</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>This dissertation is structured around three specific research aims:</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>**Specific Aim 1: Develop an AI-Powered System for Methodological Gap Analysis.** This aim focuses on the engineering and validation of the ETL+RAG pipeline, a tool designed to systematically process scientific literature and identify under-explored research methodologies in data-intensive fields.</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>**Specific Aim 2: Analyze the Association Between Ozone Exposure and Cardiovascular Disease Mortality.** This aim serves as a direct application of the pipeline. It involves conducting a systematic literature review to confirm the state of the science and then applying a baseline machine learning analysis (Random Forest) to a large-scale CDC dataset to explore the link between ozone and CVD mortality.</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Research Question:** To what extent do annual ozone exposure metrics predict county-level cardiovascular mortality rates in the U.S. after controlling for key covariates?</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>**Specific Aim 3: Develop a Deep Learning Framework for Monitoring Unconventional Oil and Gas Development.** Addressing the methodological gap identified by Aim 1, this aim involves creating a novel framework using CNNs and GNNs to identify UOG sites and monitor their activity via satellite data.</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Research Question:** Can a multi-modal deep learning framework, integrating high-resolution optical and methane satellite data, accurately identify and classify the activity status of UOG wells? Can the resulting inventory be used to explore associations with public health outcomes?</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="fu"># Proposed Methodology for Aim 3</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>The framework for Aim 3 will leverage **Convolutional Neural Networks (CNNs)** to analyze **multi-modal satellite imagery** (e.g., high-resolution optical, Sentinel-5P methane data) for object detection and classification. The goal is to move beyond simple site identification and create a detailed, actionable inventory of UOG infrastructure. As illustrated in the conceptual example @fig-well-concept, the model will be trained to identify key components within a well site, such as:</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="al">![Well pad Concept](figures\contrst.PNG)</span>{#fig-well-concept}</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Well pad** (yellow)  </span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Storage tanks** (purple)  </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Vehicle fleets** (red)  </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>These components serve as proxies for site activity levels.</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>To dramatically improve computational efficiency and model performance, a novel **pre-processing step** will be implemented:</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Mask creation**  </span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Leverage publicly available county tax parcel data  </span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Programmatically exclude areas where UOG development is highly improbable (residential zones, protected lands, commercial districts)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Focused analysis**  </span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Significantly reduce the geographic search space  </span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Enable more intensive modeling on the remaining, high-likelihood parcels</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>The final output will be a comprehensive, geolocated dataset of UOG sites and their components, which is essential for future environmental exposure and health impact studies.  </span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>A complete, detailed breakdown of this methodology, including the phased implementation plan and specific model architectures, is provided in the chapter on the <span class="co">[</span><span class="ot">Proposed Deep Learning Framework for UOG Site Monitoring (Aim 3)</span><span class="co">](05-aim3.qmd#sec-aim-three)</span>.</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="fu"># Application Scenario</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>**As a first application to validate the pipeline (Aim 1), the ETL &amp; RAG system will facilitate** a systematic review of research intersecting:</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Ozone exposure and health outcomes (heart disease).</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Geospatial epidemiological techniques.</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Machine learning methodologies.</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>Through semantic querying, the pipeline will explicitly reveal:</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Commonly applied geospatial analysis techniques (spatial regression, kriging, hotspot analysis).</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prevalent machine learning methods (Random Forest, XGBoost, Neural Networks).</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Underrepresented or novel methodologies within existing literature.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>**The insights gained from this initial review will directly inform the baseline analysis in Aim 2 and the selection of advanced deep learning methods for the novel framework in Aim 3**, demonstrating the value of the ETL and RAG tools in launching a multi-stage research program.</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="fu"># Personal Motivation &amp; Investment</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>Manual literature reviews and data extraction are notoriously time-consuming. Recognizing these limitations, and anticipating the computational demands of the proposed research aims, I personally invested in specialized hardware (multiple GPUs, 512 GB RAM, upgraded motherboard). This local high-performance computing environment is essential for handling the full scope of this dissertation, including: **large-scale PDF processing for Aim 1; geospatial analysis and ML model training for Aim 2; and, most critically, the development and training of state-of-the-art deep learning models for Aim 3, which involves processing vast satellite imagery datasets and multi-modal data streams (optical, methane, vector).**</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>This investment reduces reliance on restrictive university cluster computing protocols and costly API services, ensuring the economic and logistical sustainability required for a project of this scale and complexity.</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="fu"># Why It’s Interesting</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Interdisciplinary Impact**: Applicable to diverse research domains beyond epidemiology and environmental health.</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Innovation Alignment**: The focus on AI-driven geospatial analysis is potentially valuable to institutions such as UAlbany’s AI Plus Institute.</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Flexible Framework**: Easily adaptable for analyzing unstructured datasets outside academic literature.</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Novel Environmental Monitoring:** **Introduces a state-of-the-art deep learning framework for monitoring industrial activity at a national scale, creating a new, publicly valuable dataset for environmental health research and policy.**</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="fu"># Timeline</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>This dissertation is structured across three primary aims, with a projected timeline spanning approximately two academic years.</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>**Year 1, Semester 1**</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Primary Aim:** Aim 1</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Tasks:** Finalize ETL+RAG pipeline development, complete GUI, conduct large-scale literature ingestion for ozone-CVD review</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>**Year 1, Semester 2**</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Primary Aim:** Aim 2</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Tasks:** Perform preliminary analysis of ozone-CVD data, write up literature review (Chapter 3) and baseline analysis (Chapter 4).</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>**Year 2, Semester 1**</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Primary Aim:** Aim 3</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Tasks:** Acquire and preprocess optical and methane satellite data. Develop, train, and validate the CNN model for UOG site identification.</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>**Year 2, Semester 2**</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Primary Aim:** Aim 3</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Tasks:** Integrate methane data for activity classification. Develop GNN framework for analysis. Finalize analysis and write-up of Aim 3.</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>**Final Months**     </span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**All Aims**  Synthesize all chapters, complete final dissertation document, and prepare for defense.                                  </span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="fu"># Interdisciplinary Collaboration and Cross-Domain Utility</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>Retrieval-Augmented Generation (RAG) facilitates interdisciplinary research by connecting knowledge domains through new data incorporation during generation (@luu_bioinspiredllm_2023). RAG-powered academic search tools enable complex, natural language queries, improving cross-field literature synthesis over traditional methods (@j_bolanos_artificial_2024). RAG’s integration into LLMs enhances their adaptability for diverse research applications <span class="co">[</span><span class="ot">@lee_bring_2024</span><span class="co">]</span>, demonstrated by systems that retrieve precise COVID-19 health information (@upadhyayEnhancingHealthInformation2025) or integrate findings on sustainable biomaterials.</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>Knowledge graph-based methods promote interdisciplinary collaboration by mapping research concepts across domains via graph mining in literature analytics (@j_bolanos_artificial_2024). Platforms like NetMe 2.0 create interactive knowledge graphs from biomedical literature, allowing shared exploration of connections by diverse specialists (@di_maria_netme_2024). Aligning LLMs with domain knowledge graphs improves multi-hop reasoning across distinct corpora (@dernbach_glam_2024). Logic-Augmented Generation allows experts from multiple fields to collaboratively build and reconcile knowledge (@gangemi_logic_2025). LLM-driven ontology creation also integrates varied datasets from different domains, such as urban systems, to improve interdisciplinary data sharing (@tupayachi_towards_2024).</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interdisciplinary Impact Example</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>Beyond its application in geospatial epidemiology, the inherent flexibility of the AI-Powered ETL &amp; RAG system architecture makes it directly applicable to other complex, data-intensive research domains such as Life Cycle Assessment (LCA) for agricultural systems, particularly concerning cover crop GWP and the compilation of Life Cycle Inventories (LCI). The existing ETL pipeline (including fast_pubmed.py, fast_openalex.py) can be readily aimed at literature pertaining to LCA, GWP, and cover crop management. The core field_extraction.py module, configurable via etl_config.json and the project's GUI (config_tab.py), is already equipped with extraction fields highly pertinent to LCA/LCI. Specifically, pre-defined fields such as "LCA System Boundaries", "Environmental Impact Categories", "Management Practices and Operational Details", and the structured "Metrics" field (designed to capture {"Metric": "name", "Value": "value", "Unit": "unit"}) are directly suited for systematically extracting quantitative LCI data (fertilizer inputs, fuel consumption, emission values, crop yields) and qualitative contextual information from a large corpus of relevant scientific articles.</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>The system’s capacity for knowledge structuration further enhances its utility for LCA/GWP research. The extensive existing knowledge base, comprising over 25 dictionaries with approximately 10,000 synonyms managed via dictionaries_gui.py (from dictionaries_config.json), includes relevant lexicons like "AGRONOMIC_MGMT_PRACTICES_SYNONYMS", "ENVIRONMENTAL_IMPACT_CATEGORIES", "COVER_CROP_SYNONYMS", and "SOIL_TYPE_SYNONYMS". These require only clicking a few checkboxes for LCA-specific terminology (specific LCI flow names, impact assessment methods, GWP characterization factors) within the GUI rather than development from scratch. The extracted and semantically unified data, including detailed LCI parameters and GWP values, is then processed by kg_pipeline.py to construct a domain-specific knowledge graph. This KG can serve as a queryable, literature-derived database of LCI components and GWP factors, enabling systematic comparison of different cover crop systems, validation of LCI data, and benchmarking of GWP model results, such as those from the previously developed Random Forest analysis for GWP_Total.</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>This application to LCA/GWP research effectively demonstrates the system's broader "Interdisciplinary Impact" and its function as a "Flexible Framework" capable of large-scale, structured data extraction and analysis from scientific literature across diverse domains. By selecting fields within the GUI to prioritize LCA-relevant fields and refining the domain-specific dictionaries, the pipeline can efficiently build a comprehensive knowledge base to support detailed LCA studies and contextualize empirical GWP findings. This not only addresses specific research needs within agricultural systems analysis but also validates the core design principles of the ETL+RAG system for robust and adaptable automated literature analytics.</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="fu"># Societal Impact and Real-World Applications</span></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>AI-driven literature review systems provide societal benefits in public health and epidemiology by accelerating research timelines. For example, AI reduced data extraction time for a diabetic retinopathy review from 1,310 minutes to 5 minutes (@gue_evaluating_2024), and an LLM completed a literature review in 17 hours compared to 100 hours for humans (@tsai_comparative_2024). This efficiency supports quicker synthesis of findings that can influence policy development (@j_bolanos_artificial_2024). AI screening also minimizes costs while preserving high recall in evidence synthesis. These systems maintain high accuracy, with GPT-4 achieving 99% reviewer accuracy in systematic review tasks (@fleurence_generative_2024).</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>Retrieval-Augmented Generation (RAG) contributes by enhancing AI output reliability and factuality. A RAG system achieved 86% diagnostic accuracy and 95% accuracy in citing sources, aiding hallucination detection (@tozuka_application_2024). RAG is a recognized strategy to mitigate hallucinations, improve factuality (@huangSurveyHallucinationLarge2024; @aditya_understanding_2024), and enhance topical relevance with factual accuracy in health information retrieval <span class="co">[</span><span class="ot">@upadhyayEnhancingHealthInformation2025</span><span class="co">]</span>.</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a><span class="fu"># Ethical Considerations and Responsible AI Implementation</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>Automated literature extraction and synthesis systems raise specific ethical issues requiring careful management. Transparency, risk classification, and fairness-accountability-transparency-ethics (FATE) measures are necessary, aligning with regulations like the EU AI Act (@j_bolanos_artificial_2024). Systems require explicit bias mitigation strategies to prevent skewed evidence bases from automated screening (@tsai_comparative_2024). The use of generative AI for scholarly tasks underscores the need for formal ethical guidelines and researcher training (@yuan_leveraging_2024). Factual inaccuracies and hallucinations in foundation models present threats to scientific rigor if not addressed (@fleurence_generative_2024). Additionally, these systems pose privacy and data protection challenges due to the risk of large models memorizing and reproducing sensitive data, necessitating compliance with HIPAA, GDPR, and the EU AI Act.</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="fu"># Literature Review {#sec-proposal-lit-review}</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a><span class="al">![Graphical Abstract](figures/ETL_RAG.png)</span>{#fig-graph-abstract}</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>Retrieval-Augmented Generation (RAG) is a machine-learning framework combining information retrieval with deep-learning models, such as transformer-based large language models <span class="co">[</span><span class="ot">@rawsonNgaAraWhakamana2024</span><span class="co">]</span>. This approach enhances factual accuracy, coherence, and context relevance of generated responses by incorporating retrieved information into the generation process <span class="co">[</span><span class="ot">@liAugmentingLargeLanguage2024</span><span class="co">]</span>. Within geospatial epidemiology, particularly concerning ozone exposure and heart disease, RAG offers a tool for synthesizing spatial and temporal data from environmental and health datasets. By integrating parametric memory of large language models with non-parametric external knowledge bases, RAG supports researchers. For example, RAG can help identify critical knowledge gaps and underrepresented methodologies <span class="co">[</span><span class="ot">@barnettSevenFailurePoints2024</span><span class="co">]</span>, and improve the factual accuracy of health information <span class="co">[</span><span class="ot">@upadhyayEnhancingHealthInformation2025</span><span class="co">]</span>, advancing the understanding of chronic disease risk factors.</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a><span class="fu">## Technical Background</span></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>RAG combines deep learning with traditional information retrieval, integrating parametric and non-parametric memory systems to enhance text generation accuracy. The parametric component involves transformer-based neural models, such as sequence-to-sequence architectures (BART, T5, LLaMA), that store learned information within model weights and can be fine-tuned for specific tasks <span class="co">[</span><span class="ot">@rawsonNgaAraWhakamana2024; @fengRetrievalGenerationSynergyAugmented2024</span><span class="co">]</span>. Non-parametric memory relies on external databases indexed as dense vector representations, queried using neural retrievers like Dense Passage Retriever (DPR) or dual-encoder architectures, enabling retrieval of contextually relevant information without model retraining <span class="co">[</span><span class="ot">@rawsonNgaAraWhakamana2024; @sakarMaximizingRAGEfficiency2024</span><span class="co">]</span>. Transformer-based architectures are employed in RAG pipelines for their language modeling capabilities, facilitating coherent and contextually informed responses. The combination of transformer generators and retrieval encoders improves accuracy, relevance, and freshness of generated content by leveraging external, updateable knowledge bases <span class="co">[</span><span class="ot">@fanSurveyRAGMeeting2024; @wangSearchingBestPractices2024</span><span class="co">]</span>. RAG systems bridge gaps between static, trained model knowledge and evolving external data sources, often outperforming traditional NLP methods in factual precision and resource efficiency <span class="co">[</span><span class="ot">@liAugmentingLargeLanguage2024; @upadhyayEnhancingHealthInformation2025</span><span class="co">]</span>.</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a><span class="fu">## Empirical Evidence and Performance Evaluation of RAG Systems</span></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>Empirical evaluation of RAG assesses its enhancement of factual accuracy, retrieval effectiveness, and efficiency in text generation. Studies like @fatehaliAutomatedLiteratureReview2024 compared RAG-based pipelines against conventional NLP approaches, including transformer-only models and frequency-based topic modeling, finding RAG superior based on higher ROUGE-1 (0.364) and ROUGE-2 (0.123) scores. @upadhyayEnhancingHealthInformation2025 demonstrated RAG’s effectiveness in health-information retrieval, nearly doubling performance metrics like CAM NDCG (0.2146 vs. 0.1119) and CAM MAP (0.1079 vs. 0.0455) compared to non-RAG systems. A central hypothesis is that integrating retrieval with generation boosts the accuracy, reliability, and contextual relevance of outputs.</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>Studies employed experimental designs comparing RAG models with multiple baselines, including transformer-based models (T5, GPT-3.5), frequency-based methods (spaCy), and traditional IR techniques (BM25). Data sources included academic corpora, scientific literature collections, and clinical notes, selected for relevance, quality, and representativeness <span class="co">[</span><span class="ot">@liAugmentingLargeLanguage2024; @rawsonNgaAraWhakamana2024; @shah-mohammadiUtilizingRAGGPT42024</span><span class="co">]</span>. Common evaluation metrics included ROUGE scores, precision, recall, F1-scores, CAM-MAP, and CAM-NDCG, assessing textual relevance, accuracy, and coherence.</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>Quantitative results from empirical studies indicate RAG’s improved performance in generating contextually accurate and relevant outputs. For example, @kreimeyerUsingRetrievalAugmentedGeneration2024 reported RAG reproducing over 80% of expert-curated information in oncology literature, indicating reliability and precision. @guProbabilisticMedicalPredictions2024 demonstrated RAG's efficiency gains by reducing manual systematic review extraction time from 1.310 minutes to 5 minutes, without sacrificing data quality. These studies highlight RAG’s strengths but also emphasize managing retrieval parameters (e.g., chunk size, embedding strategies) to avoid retrieval inaccuracies or context misalignment <span class="co">[</span><span class="ot">@barnettSevenFailurePoints2024</span><span class="co">]</span>.</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a><span class="fu">## Applications in Systematic Reviews and Evidence Synthesis</span></span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>RAG streamlines evidence collection in systematic reviews by combining parametric and non-parametric memory systems. These systems pair neural sequence-to-sequence generators with dense-vector indices queried by neural retrievers, automating the identification and extraction of relevant literature <span class="co">[</span><span class="ot">@rawsonNgaAraWhakamana2024; @sakarMaximizingRAGEfficiency2024</span><span class="co">]</span>. This automation reduces the manual workload associated with literature screening and data extraction. For instance, GPT-3.5 Turbo with RAG reduced data extraction time in systematic reviews from 1,310 minutes to 5 minutes, maintaining high concordance with human reviewers for extracting structured data <span class="co">[</span><span class="ot">@guProbabilisticMedicalPredictions2024</span><span class="co">]</span>.</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>RAG also enhances the accuracy and consistency of data extraction processes. In health information retrieval tasks, RAG-driven models demonstrated improved topical relevance and factual accuracy, with improved performance metrics such as CAM-MAP and CAM-NDCG compared to traditional information retrieval methods <span class="co">[</span><span class="ot">@upadhyayEnhancingHealthInformation2025</span><span class="co">]</span>. Furthermore, RAG with quantized LLMs improves data extraction accuracy (exceeding 93%) while reducing computational resource demands <span class="co">[</span><span class="ot">@ranjanmaharanaRetrievalAugmentedGeneration2024</span><span class="co">]</span>. These approaches improve efficiency and can mitigate human biases, aiding uniformity in evidence synthesis.</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a>Advanced RAG implementations in systematic reviews leverage semantic search capabilities through dense-vector indices and neural retrieval methods. This approach often retrieves literature with greater contextual understanding than conventional keyword-based searches. When such retrieval is combined with large language models for generation, it can support the identification of relevant and potentially overlooked literature. Recent empirical studies illustrate that integrating RAG into literature review processes yields better summarization accuracy, with measurable improvements in ROUGE metrics compared to other NLP methods <span class="co">[</span><span class="ot">@fatehaliAutomatedLiteratureReview2024</span><span class="co">]</span>. This demonstrates RAG’s capability to provide accurate, contextually relevant summaries for high-quality evidence synthesis.</span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a><span class="fu">## Applications in Public Health and Epidemiology</span></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>RAG applications in Public Health and Epidemiology enhance information synthesis and decision-making. RAG systems ground responses in current, domain-specific evidence by incorporating information from diverse sources like clinical guidelines and surveillance data, improving factual accuracy <span class="co">[</span><span class="ot">@rawsonNgaAraWhakamana2024;@liAugmentingLargeLanguage2024</span><span class="co">]</span>. This capability aids public health professionals in synthesizing evolving information for interventions. Examples include updating knowledge bases for health worker training <span class="co">[</span><span class="ot">@alghadbanTransformingHealthcareEducation2023</span><span class="co">]</span>, streamlining surveillance via clinical note data extraction <span class="co">[</span><span class="ot">@shah-mohammadiUtilizingRAGGPT42024</span><span class="co">]</span>, and processing large document sets for key point summarization with tools like 'Cognitive Reviewer' <span class="co">[</span><span class="ot">@barnettSevenFailurePoints2024</span><span class="co">]</span>. RAG also automates accurate structured dataset creation from literature <span class="co">[</span><span class="ot">@ranjanmaharanaRetrievalAugmentedGeneration2024</span><span class="co">]</span>. Policy experts recognize RAG for improving accuracy in evidence synthesis <span class="co">[</span><span class="ot">@fleurenceGenerativeAIHealth2024a</span><span class="co">]</span>.</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>In health communication and public engagement, RAG contributes to generating clear, accurate, and personalized health information. For instance, RAG integrated into models for breast-cancer nursing care questions yielded high user-rated accuracy and empathy <span class="co">[</span><span class="ot">@xuEvaluationIntegrationRetrievalaugmented2024</span><span class="co">]</span>. RAG-driven systems are also used to train frontline health workers by providing traceable, guideline-based information adaptable to evolving clinical knowledge <span class="co">[</span><span class="ot">@alghadbanTransformingHealthcareEducation2023</span><span class="co">]</span>. By enhancing topical relevance and factual accuracy in consumer health information retrieval and constraining hallucinations, RAG contributes to reliable health education and efforts against misinformation <span class="co">[</span><span class="ot">@upadhyayEnhancingHealthInformation2025</span><span class="co">]</span>.</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a><span class="fu">## Identification of Methodological Gaps using Retrieval-Augmented Generation</span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>RAG can be a meta-analytic tool to identify methodological gaps by processing scientific literature. RAG deployments map 'failure points' in various workflows, pinpointing areas with weak or insufficient methodologies <span class="co">[</span><span class="ot">@barnettSevenFailurePoints2024</span><span class="co">]</span>. For example, by analyzing large datasets, RAG reveals under-explored techniques like low-resource quantized LLMs, offering efficiency and accuracy benefits overlooked in conventional dataset-building <span class="co">[</span><span class="ot">@ranjanmaharanaRetrievalAugmentedGeneration2024</span><span class="co">]</span>. This capability allows surveying current methods and identifying areas lacking detailed research.</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>RAG application in benchmarking and comparative analysis exposes inconsistencies and under-researched areas. When used for evaluations, such as in multilingual medical question answering, RAG reveals performance drops in contexts like non-English languages, underscoring methodological blind spots or areas where methods lack robustness <span class="co">[</span><span class="ot">@alonsoMedExpQAMultilingualBenchmarking2024</span><span class="co">]</span>. Highlighting performance discrepancies helps recognize variations in methodological effectiveness or under-defined methods, surfacing research gaps <span class="co">[</span><span class="ot">@barnettSevenFailurePoints2024</span><span class="co">]</span>.</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>Insights from RAG application guide selecting and refining future research methodologies. RAG spotlights actionable improvements; for example, quantized LLMs reducing computational demand while improving accuracy suggests a methodological shift <span class="co">[</span><span class="ot">@ranjanmaharanaRetrievalAugmentedGeneration2024</span><span class="co">]</span>. RAG systems also recommend analytical strategies, such as guiding target selection in drug design or suggesting techniques to overcome limitations in traditional methods, informing future research <span class="co">[</span><span class="ot">@zhangBiSpecPairwiseAI2024;@xuAutomatingBibliometricAnalysis2024</span><span class="co">]</span>.</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a><span class="fu">## Discussion</span></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>The development of this automated Extract, Transform, Load (ETL) and Retrieval-Augmented Generation (RAG) pipeline was undertaken as a direct response to the inherent challenges of identifying a novel and impactful research topic within a complex domain like geospatial epidemiology. As highlighted in our course's "Advice on Research," selecting a research problem carefully, focusing on fundamentals, and finding a unique perspective in potentially crowded areas are crucial early steps. This system was engineered to provide a systematic and efficient methodology for this discovery process, using the intersection of ozone exposure, heart disease, and geospatial/machine learning techniques as its initial proving ground.</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>The pipeline's architecture is tailored to facilitate an iterative research discovery workflow, as outlined in the project's data collection and integration strategy. The rapid ETL phase, capable of processing hundreds of articles in minutes using modules like fast_pubmed.py and GPU-accelerated Docling <span class="co">[</span><span class="ot">@auerDoclingTechnicalReport2024</span><span class="co">]</span>, allows for an initial broad sweep of the literature. Subsequently, the integration of Latent Dirichlet Allocation (LDA) via topic_modeling_culda.py enables the automated categorization of this literature and, crucially, the identification of "weakly populated or contradictory clusters," which serve as indicators of potential knowledge gaps or under-explored methodological niches. This aligns with the goal of finding less "crowded" research areas. The system then leverages these insights to refine search queries, allowing for a more targeted collection of literature to deepen understanding around these identified gaps. This iterative process of broad collection, gap identification via topic modeling and LLM interpretation, and refined collection is central to the system's utility in topic formulation.</span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>Furthermore, the RAG component, with its knowledge graph integration (Neo4j, kg_pipeline.py, inspired by @tuMitigatingGrandChallenges2024) and novel Reciprocal-Rank Fusion (RRF) for precise retrieval, allows for nuanced exploration of these identified gaps. It enables users to query the enriched, gap-focused corpus to understand existing methodologies and pinpoint specific underrepresented geospatial or machine learning approaches. The high metadata similarity scores (Levenshtein &gt;0.90) and stringent QA processes aim to ensure that the insights derived are based on accurate data, supporting the selection of a research question that is both relevant and methodologically sound. The system's current application to the literature on ozone exposure and heart disease, with the intent to link findings to CDC datasets, serves as a practical demonstration of how this pipeline can navigate from a broad area of interest to a specific, data-informed research question, thereby operationalizing the principles of effective research topic selection. The pipeline doesn't just automate literature review; it structures the exploratory phase of research itself.</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusion</span></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>The primary contribution of this work is the development and practical demonstration of an automated ETL+RAG pipeline designed as a robust tool for systematically identifying research gaps and formulating novel research questions in complex scientific fields such as geospatial epidemiology. This system directly addresses the challenge of selecting a meaningful research topic by providing an efficient, scalable, and transparent framework for navigating and analyzing vast quantities of academic literature. By integrating rapid data ingestion, advanced PDF content extraction, iterative topic modeling for gap identification, and sophisticated RAG capabilities, the pipeline operationalizes key advice for effective research, enabling a structured approach to move from broad exploration to specific, actionable research directions.</span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>The value of this pipeline lies in its capacity to empower researchers, particularly those embarking on new projects or exploring interdisciplinary areas, to efficiently discover under-explored methodological niches or substantive knowledge gaps. In the context of this project, it has laid the groundwork for pinpointing underrepresented geospatial and machine learning techniques in the study of ozone exposure and heart disease. More broadly, this process-oriented tool offers a significant advancement over traditional manual methods, demonstrating how AI can be leveraged not just for data analysis, but for the foundational stage of research discovery itself, fostering methodologically sound and impactful inquiry.</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a><span class="fu">## Future Directions</span></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>Future development of this ETL+RAG pipeline will focus on enhancing its efficacy as a research discovery tool and broadening its application. A key priority is the refinement of the quality assurance (QA) process to reduce the "occasional false negatives" and improve the precision of gap identification. This involves exploring more dynamic error detection and advanced hallucination mitigation strategies for the LLM components <span class="co">[</span><span class="ot">@huangSurveyHallucinationLarge2024; @fanSurveyRAGMeeting2024</span><span class="co">]</span>.</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>From a research process perspective, the immediate next step involves applying the methodologies identified by the pipeline to the large-scale CDC datasets on ozone and heart disease. This will involve implementing relevant machine learning approaches (e.g., Random Forest, geospatial cross-validation) to analyze these datasets, thereby empirically validating the research gap identified by the pipeline and completing the class project's analytical component. The insights from this application will also serve as a feedback loop for further refining the pipeline's gap identification capabilities.</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>Further enhancements to the pipeline itself will include exploring computational efficiencies, such as the integration of quantized LLMs <span class="co">[</span><span class="ot">@ranjanmaharanaRetrievalAugmentedGeneration2024</span><span class="co">]</span> and optimized retrieval mechanisms <span class="co">[</span><span class="ot">@wangSearchingBestPractices2024</span><span class="co">]</span>, to manage costs and improve processing speeds for even larger literature corpora. Incorporating more sophisticated uncertainty-aware retrieval <span class="co">[</span><span class="ot">@dholeRetrieveNotRetrieve2025</span><span class="co">]</span> and explicit bias detection mechanisms <span class="co">[</span><span class="ot">@liAugmentingLargeLanguage2024</span><span class="co">]</span> will also be critical. Finally, the modular design of the pipeline lends itself to expansion. Future work will aim to test its generalizability by applying it to identify methodological gaps in other epidemiological areas and diverse scientific domains, potentially fine-tuning domain-specific LLMs to enhance its utility for a wider range of research discovery tasks.</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data Management</span></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>This dissertation will integrate three distinct categories of data, each corresponding to a specific research aim.</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="fu">## Scholarly Literature Corpus (for Aim 1)</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sources:** PubMed, OpenAlex, and Scopus for article metadata; Unpaywall and publisher websites for full-text PDFs.</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Volume:** An initial corpus of up to 1,000 PDF articles, with the system designed to scale to several thousand.</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Formats:** Source metadata (JSON), extracted article content (Markdown), structured data (Feather files), and semantic embeddings stored in a Qdrant vector database.</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a><span class="fu">## Public Health and Environmental Datasets (for Aim 2)</span></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sources:** U.S. Centers for Disease Control and Prevention (CDC) Wonder and Data.gov portals.</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Specific Datasets:** Daily census-tract level ozone concentrations (2001-2014); county-level cardiovascular disease mortality rates (2000-2019); and U.S. Census data for demographic covariates.</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Volume:** Tens of gigabytes, comprising over 400 million row-level observations in the source files.</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Formats:** CSV files, which will be processed and stored in the efficient Feather format for analysis.</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a><span class="fu">## Geospatial and Remote Sensing Imagery (for Aim 3)</span></span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sources:** Public and commercial satellite data providers.</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>**Optical Imagery:** High-resolution (0.5m - 2m) multi-spectral imagery from sources such as the National Agriculture Imagery Program (NAIP), Planet, or Maxar.</span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>**Methane Data:** High-resolution methane concentration data from emerging platforms like MethaneSAT, Carbon Mapper, and GHGSat.</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>**Contextual Data:** Geocoded tax parcel data from county governments and LULC data from the USGS.</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Volume:** Terabytes of raster and vector data covering large geographical areas of interest.</span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Formats:** GeoTIFF (for raster imagery), Shapefile or GeoJSON (for vector data), and CSVs.</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a><span class="fu"># Expected Results</span></span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>The successful completion of this dissertation will yield four primary outcomes, with each of the first three corresponding directly to a specific research aim.</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="fu">## A Novel AI-Powered Literature Analysis Pipeline (from Aim 1)</span></span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A complete, open-source Python-based ETL and RAG pipeline that enables the seamless, automated ingestion, extraction, and analysis of scientific literature to systematically identify methodological research gaps.</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="fu">## A Baseline Model of Ozone's Impact on Cardiovascular Health (from Aim 2)</span></span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A robust machine learning analysis quantifying the association between various ozone exposure metrics and county-level CVD mortality in the U.S. This will serve as a critical baseline and a direct application of the gap-finding pipeline.</span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a><span class="fu">## A State-of-the-Art Framework and Inventory for UOG Monitoring (from Aim 3)</span></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A validated deep learning framework (CNN/GNN) capable of identifying and classifying the activity status of UOG sites at scale using multi-modal satellite data. The primary deliverable will be a novel, high-resolution spatiotemporal inventory of UOG wells, providing a foundational dataset for future environmental health research.</span>
<span id="cb1-275"><a href="#cb1-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-276"><a href="#cb1-276" aria-hidden="true" tabindex="-1"></a><span class="fu">## Comprehensive Documentation and Dissemination</span></span>
<span id="cb1-277"><a href="#cb1-277" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A final dissertation document and an interactive Quarto-based report demonstrating the literature-derived insights, the baseline geospatial analysis, and the innovative deep learning framework and its outputs.</span>
<span id="cb1-278"><a href="#cb1-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-279"><a href="#cb1-279" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-280"><a href="#cb1-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-281"><a href="#cb1-281" aria-hidden="true" tabindex="-1"></a><span class="fu"># Example data extraction functions </span></span>
<span id="cb1-282"><a href="#cb1-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-283"><a href="#cb1-283" aria-hidden="true" tabindex="-1"></a>In this section, I provide sample code snippets that I’ve developed for the ETL pipeline. Each function targets a specific stage: PubMed metadata fetching, PDF retrieval from Unpaywall, Docling-based text extraction, Zotero integration, etc.</span>
<span id="cb1-284"><a href="#cb1-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-285"><a href="#cb1-285" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `fast_pubmed.py`</span></span>
<span id="cb1-286"><a href="#cb1-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-287"><a href="#cb1-287" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-288"><a href="#cb1-288" aria-hidden="true" tabindex="-1"></a>A drop-in turbo-replacement for the two original helpers:</span>
<span id="cb1-289"><a href="#cb1-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-290"><a href="#cb1-290" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`pubmed_search_chunked`</span></span>
<span id="cb1-291"><a href="#cb1-291" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`fetch_pubmed_metadata`</span></span>
<span id="cb1-292"><a href="#cb1-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-293"><a href="#cb1-293" aria-hidden="true" tabindex="-1"></a>**Key features:**</span>
<span id="cb1-294"><a href="#cb1-294" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>&lt; 1 s single <span class="in">`esearch`</span> to collect up-to-10,000 PMIDs.</span>
<span id="cb1-295"><a href="#cb1-295" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Thread-pooled, rate-limited bulk-<span class="in">`efetch`</span> (≤ 3 req/s/IP – NCBI TOS).</span>
<span id="cb1-296"><a href="#cb1-296" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Parses the same rich metadata as previously used: Authors, Date, Journal, Volume, Issue, Pages, plus Title / DOI / Abstract.</span>
<span id="cb1-297"><a href="#cb1-297" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Robust logging with granular exception capture; a bad article never aborts the batch.</span>
<span id="cb1-298"><a href="#cb1-298" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>No hard-wired globals; everything is configurable via keyword args.</span>
<span id="cb1-299"><a href="#cb1-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-300"><a href="#cb1-300" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `fast_openalex.py`</span></span>
<span id="cb1-301"><a href="#cb1-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-302"><a href="#cb1-302" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-303"><a href="#cb1-303" aria-hidden="true" tabindex="-1"></a>A Python module for rapidly querying and retrieving scholarly records from the OpenAlex API, designed to complement PubMed searches by capturing literature not indexed in PubMed. Utilizing asynchronous I/O and parallel processing, this tool fetches article metadata at scale, parsing and formatting results into a convenient DataFrame for immediate integration into the analysis pipeline.</span>
<span id="cb1-304"><a href="#cb1-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-305"><a href="#cb1-305" aria-hidden="true" tabindex="-1"></a>**Key Features:**</span>
<span id="cb1-306"><a href="#cb1-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-307"><a href="#cb1-307" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**High-Speed Retrieval:** Uses asynchronous API requests (<span class="in">`aiohttp`</span>) and concurrent fetching to maximize throughput while respecting rate limits.</span>
<span id="cb1-308"><a href="#cb1-308" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Efficient Pagination:** Automatically handles pagination and cursor-based retrieval, fetching results swiftly and transparently.</span>
<span id="cb1-309"><a href="#cb1-309" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Robust Parsing and Cleaning:** Extracts and cleans metadata such as DOI, abstracts, authorship, publication dates, journal information, and page ranges, ensuring standardized, analysis-ready outputs.</span>
<span id="cb1-310"><a href="#cb1-310" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Easy Integration:** Provides a simple wrapper (<span class="in">`search_works_df`</span>) that returns results in a Pandas DataFrame consistent with existing data processing workflows.</span>
<span id="cb1-311"><a href="#cb1-311" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Polite API Interaction:** Adheres strictly to recommended OpenAlex rate limits, ensuring reliable, long-term API access without throttling.</span>
<span id="cb1-312"><a href="#cb1-312" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Configurable &amp; Flexible:** Easily adjustable query parameters, such as items per page, concurrency level, and query-per-second rate, allow for custom optimizations.</span>
<span id="cb1-313"><a href="#cb1-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-314"><a href="#cb1-314" aria-hidden="true" tabindex="-1"></a>Ideal for comprehensive literature reviews, systematic analyses, and dataset augmentation tasks that require accessing a broader scope of scholarly publications beyond traditional indexing services like PubMed.</span>
<span id="cb1-315"><a href="#cb1-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-316"><a href="#cb1-316" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `etl_elsevier.py`</span></span>
<span id="cb1-317"><a href="#cb1-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-318"><a href="#cb1-318" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-319"><a href="#cb1-319" aria-hidden="true" tabindex="-1"></a>A  Python module for retrieving scholarly articles from Elsevier's Scopus database, integrating with the existing ETL workflow. It uses asynchronous requests (aiohttp) to fetch article metadata, enriches records via Crossref, and handles data parsing, error management, and structured data outputs.</span>
<span id="cb1-320"><a href="#cb1-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-321"><a href="#cb1-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-322"><a href="#cb1-322" aria-hidden="true" tabindex="-1"></a>**Main Functionalities:**</span>
<span id="cb1-323"><a href="#cb1-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-324"><a href="#cb1-324" aria-hidden="true" tabindex="-1"></a>The module retrieves metadata from Scopus using paginated requests while adhering to Elsevier's API rate limits and parsing key metadata such as DOI, Scopus ID, titles, and journal information. It concurrently enriches this data with additional details from Crossref, including authors, abstracts, and PDF links, incorporating error handling, retries, and standardized field formatting. Configuration settings—including API credentials, endpoints, rate limits, concurrency, and logging—are managed externally via a JSON file (<span class="in">`etl_config.json`</span>), which supports flexible adjustments and provides detailed logging for error tracking. The final enriched metadata is structured into Pandas DataFrames with standardized columns optimized for downstream ETL workflows.</span>
<span id="cb1-325"><a href="#cb1-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-326"><a href="#cb1-326" aria-hidden="true" tabindex="-1"></a>**Key Features:**</span>
<span id="cb1-327"><a href="#cb1-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-328"><a href="#cb1-328" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Asynchronous Requests:** Utilizes asyncio/aiohttp for scalable, concurrent API requests, improving throughput.</span>
<span id="cb1-329"><a href="#cb1-329" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Flexible Configuration:** All configurations (API keys, search parameters, file paths) managed via external JSON for flexibility.</span>
<span id="cb1-330"><a href="#cb1-330" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Robust Parsing &amp; Data Integrity:** Implements metadata parsing with safeguards to maintain data quality.</span>
<span id="cb1-331"><a href="#cb1-331" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Comprehensive Logging:** Detailed logging provides real-time insights into data fetching, processing status, and error handling.</span>
<span id="cb1-332"><a href="#cb1-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-333"><a href="#cb1-333" aria-hidden="true" tabindex="-1"></a>Ideal for comprehensive literature reviews, systematic analyses, and dataset augmentation tasks that require accessing a broader scope of scholarly publications beyond traditional indexing services like PubMed.</span>
<span id="cb1-334"><a href="#cb1-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-335"><a href="#cb1-335" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `async_unpaywall.py`</span></span>
<span id="cb1-336"><a href="#cb1-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-337"><a href="#cb1-337" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-338"><a href="#cb1-338" aria-hidden="true" tabindex="-1"></a>A helper function for quickly retrieving full-text PDFs from the Unpaywall API given DOI identifiers. Ideal for automated bulk PDF downloads in an ETL workflow.</span>
<span id="cb1-339"><a href="#cb1-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-340"><a href="#cb1-340" aria-hidden="true" tabindex="-1"></a>**Key features:**</span>
<span id="cb1-341"><a href="#cb1-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-342"><a href="#cb1-342" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Uses Python's asynchronous libraries (<span class="in">`asyncio`</span> + <span class="in">`aiohttp`</span>) for concurrent fetching.</span>
<span id="cb1-343"><a href="#cb1-343" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Adheres to Unpaywall’s API limits (≤ 8 requests per second).</span>
<span id="cb1-344"><a href="#cb1-344" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Supports optional proxy rotation for reliability.</span>
<span id="cb1-345"><a href="#cb1-345" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Automatically sanitizes PDF filenames, preventing file-system errors.</span>
<span id="cb1-346"><a href="#cb1-346" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>handles HTTP failures, missing PDFs, and other edge cases with logging.</span>
<span id="cb1-347"><a href="#cb1-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-348"><a href="#cb1-348" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module `docling_extract_formulas_mp_multi.py`</span></span>
<span id="cb1-349"><a href="#cb1-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-350"><a href="#cb1-350" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-351"><a href="#cb1-351" aria-hidden="true" tabindex="-1"></a>A multiprocessing-optimized PDF extraction module using Docling's layout analysis capabilities, enriched with GPU acceleration. It converts PDFs into structured text, accurately extracting  elements such as tables, equations, and formatted text.</span>
<span id="cb1-352"><a href="#cb1-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-353"><a href="#cb1-353" aria-hidden="true" tabindex="-1"></a>**Key features:**</span>
<span id="cb1-354"><a href="#cb1-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-355"><a href="#cb1-355" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Multi-process parallelization with GPU allocation for optimized throughput.</span>
<span id="cb1-356"><a href="#cb1-356" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Extracts full document text as Markdown, handling complex formatting and special characters.</span>
<span id="cb1-357"><a href="#cb1-357" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Specialized extraction for embedded LaTeX formulas and structured table data.</span>
<span id="cb1-358"><a href="#cb1-358" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>error handling and logging ensure resilience against problematic PDFs.</span>
<span id="cb1-359"><a href="#cb1-359" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Integrated token-counting for downstream NLP workflows.</span>
<span id="cb1-360"><a href="#cb1-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-361"><a href="#cb1-361" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `fast_zotero.py`</span></span>
<span id="cb1-362"><a href="#cb1-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-363"><a href="#cb1-363" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-364"><a href="#cb1-364" aria-hidden="true" tabindex="-1"></a>A helper module designed forintegration with Zotero citation management workflows. Enables batch creation of Zotero items, parallelized PDF uploads, and automatic citation formatting via local <span class="in">`citeproc`</span> rendering.</span>
<span id="cb1-365"><a href="#cb1-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-366"><a href="#cb1-366" aria-hidden="true" tabindex="-1"></a>**Key features:**</span>
<span id="cb1-367"><a href="#cb1-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-368"><a href="#cb1-368" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>batch creation of Zotero items (up to 50 items per API call).</span>
<span id="cb1-369"><a href="#cb1-369" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Parallelized PDF attachment uploads via thread pooling.</span>
<span id="cb1-370"><a href="#cb1-370" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Local citation rendering using the CSL (<span class="in">`citeproc`</span>) engine for instant citation generation without API latency.</span>
<span id="cb1-371"><a href="#cb1-371" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Optional fallback to Zotero's built-in citation rendering API if local citation rendering encounters issues.</span>
<span id="cb1-372"><a href="#cb1-372" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>customizable citation-style handling through a configurable local CSL style registry.</span>
<span id="cb1-373"><a href="#cb1-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-374"><a href="#cb1-374" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `field_extraction.py`</span></span>
<span id="cb1-375"><a href="#cb1-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-376"><a href="#cb1-376" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-377"><a href="#cb1-377" aria-hidden="true" tabindex="-1"></a>A extraction module that enhances a Feather-format DataFrame by retrieving structured metadata fields through iterative Large Language Model (LLM) calls. It uses techniques for JSON parsing, LLM response caching, tokenization, parallelized processing, and merging strategies to maintain data integrity and avoid duplication.</span>
<span id="cb1-378"><a href="#cb1-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-379"><a href="#cb1-379" aria-hidden="true" tabindex="-1"></a>**Key features:**</span>
<span id="cb1-380"><a href="#cb1-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-381"><a href="#cb1-381" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Robust JSON Parsing:** Cleans and interprets LLM-generated JSON output, handling common formatting errors.</span>
<span id="cb1-382"><a href="#cb1-382" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Intelligent LLM Caching:** Avoids redundant API calls by caching LLM responses based on prompt content hashes.</span>
<span id="cb1-383"><a href="#cb1-383" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Parallel Processing:** Employs thread pools for efficient concurrent handling of multiple data rows and text chunks.</span>
<span id="cb1-384"><a href="#cb1-384" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dynamic Text Chunking:** Splits long texts into manageable segments to stay within LLM token limits, ensuring comprehensive extraction.</span>
<span id="cb1-385"><a href="#cb1-385" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Field Unification:** Carefully merges newly extracted data with existing metadata, ensuring consistency and preventing duplication, especially within structured fields such as numeric metrics.</span>
<span id="cb1-386"><a href="#cb1-386" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Comprehensive Logging:** Detailed logging and exception handling provide transparency and facilitate troubleshooting.</span>
<span id="cb1-387"><a href="#cb1-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-388"><a href="#cb1-388" aria-hidden="true" tabindex="-1"></a>This module is particularly optimized for workflows involving complex metadata extraction scenarios, such as academic literature reviews, where accuracy, scalability, and structured data consistency are crucial.</span>
<span id="cb1-389"><a href="#cb1-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-390"><a href="#cb1-390" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `topic_modeling_gui.py`</span></span>
<span id="cb1-391"><a href="#cb1-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-392"><a href="#cb1-392" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-393"><a href="#cb1-393" aria-hidden="true" tabindex="-1"></a>A Python module for performing topic modeling on large document collections using parallelized workflows. It combines text preprocessing with Latent Dirichlet Allocation (LDA) modeling, supporting both scikit-learn and Gensim frameworks. The module emphasizes computational efficiency through parallel processing, optimized BLAS thread usage, and structured hyperparameter searches to achieve the highest-quality topic coherence.</span>
<span id="cb1-394"><a href="#cb1-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-395"><a href="#cb1-395" aria-hidden="true" tabindex="-1"></a>**Key features:**</span>
<span id="cb1-396"><a href="#cb1-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-397"><a href="#cb1-397" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Robust Preprocessing:** Efficiently cleans text by removing references, standardizing formats, tokenizing, removing stopwords, and lemmatizing.</span>
<span id="cb1-398"><a href="#cb1-398" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Parallel Processing:** Utilizes multiprocessing and threading for rapid tokenization, preprocessing, and dominant-topic extraction, significantly speeding up operations on large datasets.</span>
<span id="cb1-399"><a href="#cb1-399" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Flexible LDA Implementation:**  integrates scikit-learn's LDA models with fallback support for Gensim models, ensuring consistent performance and reliability.</span>
<span id="cb1-400"><a href="#cb1-400" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Hyperparameter Optimization:** Uses exhaustive grid search across critical LDA parameters (e.g., number of topics, bigram/trigram thresholds), optimizing for coherence scores.</span>
<span id="cb1-401"><a href="#cb1-401" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dominant Topic Identification:** Efficiently extracts and summarizes the most significant topics per document, indicating their contribution and top keywords.</span>
<span id="cb1-402"><a href="#cb1-402" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Detailed Logging and Error Handling:** Provides logging at each processing step, simplifying debugging and ensuring transparency of the modeling process.</span>
<span id="cb1-403"><a href="#cb1-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-404"><a href="#cb1-404" aria-hidden="true" tabindex="-1"></a>Ideal for research-intensive tasks such as systematic literature reviews, thematic content analysis, or exploratory text analysis, this module enhances productivity and result quality through its structured approach.</span>
<span id="cb1-405"><a href="#cb1-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-406"><a href="#cb1-406" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `kg_pipeline.py`</span></span>
<span id="cb1-407"><a href="#cb1-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-408"><a href="#cb1-408" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-409"><a href="#cb1-409" aria-hidden="true" tabindex="-1"></a>The <span class="in">`kg_pipeline.py`</span> script serves as a integration module that transforms structured article metadata and analytical results into a Knowledge Graph (KG) within a Neo4j database. It handles entity and relationship management, ensures data integrity via constraints, and uses unified terminology dictionaries for consistent entity naming.</span>
<span id="cb1-410"><a href="#cb1-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-411"><a href="#cb1-411" aria-hidden="true" tabindex="-1"></a>**Main functionalities include:**</span>
<span id="cb1-412"><a href="#cb1-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-413"><a href="#cb1-413" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Neo4j Integration**: </span>
<span id="cb1-414"><a href="#cb1-414" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Establishes connection and handles transactional updates to Neo4j.</span>
<span id="cb1-415"><a href="#cb1-415" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Uses merge operations to add/update entities such as Articles, Study Types, Soil Types, Cover Crops, and more.</span>
<span id="cb1-416"><a href="#cb1-416" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-417"><a href="#cb1-417" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Entity Unification**:  </span>
<span id="cb1-418"><a href="#cb1-418" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Applies extensive synonym unification via <span class="in">`dictionaries.py`</span> to standardize terminology across various fields, ensuring consistency and accuracy in the knowledge graph.</span>
<span id="cb1-419"><a href="#cb1-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-420"><a href="#cb1-420" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dynamic Schema Management**:</span>
<span id="cb1-421"><a href="#cb1-421" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Automatically sets up Neo4j constraints to maintain schema integrity and database performance.</span>
<span id="cb1-422"><a href="#cb1-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-423"><a href="#cb1-423" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Error Handling &amp; Logging**:  </span>
<span id="cb1-424"><a href="#cb1-424" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Comprehensive logging and exception handling facilitate easy debugging and robust data integrity verification during the KG construction process.</span>
<span id="cb1-425"><a href="#cb1-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-426"><a href="#cb1-426" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Integration with Topic Modeling**:</span>
<span id="cb1-427"><a href="#cb1-427" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Incorporates dominant topics and associated metadata, linking textual analysis results directly within the KG.</span>
<span id="cb1-428"><a href="#cb1-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-429"><a href="#cb1-429" aria-hidden="true" tabindex="-1"></a><span class="fu">## Module: `dictionaries.py`</span></span>
<span id="cb1-430"><a href="#cb1-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-431"><a href="#cb1-431" aria-hidden="true" tabindex="-1"></a>**Description:**  </span>
<span id="cb1-432"><a href="#cb1-432" aria-hidden="true" tabindex="-1"></a>This module contains dictionaries used for unifying terminology across numerous categories in the ETL pipeline. With thousands of terms and synonyms across 30+ dictionaries, it supports consistency and accuracy of entity representation within the knowledge graph.</span>
<span id="cb1-433"><a href="#cb1-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-434"><a href="#cb1-434" aria-hidden="true" tabindex="-1"></a>**Key Dictionaries Include**:</span>
<span id="cb1-435"><a href="#cb1-435" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Study Types**</span>
<span id="cb1-436"><a href="#cb1-436" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Environmental Impact Categories**</span>
<span id="cb1-437"><a href="#cb1-437" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Management Practices**</span>
<span id="cb1-438"><a href="#cb1-438" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Cover Crops**</span>
<span id="cb1-439"><a href="#cb1-439" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Tillage Practices**</span>
<span id="cb1-440"><a href="#cb1-440" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Metric Names**</span>
<span id="cb1-441"><a href="#cb1-441" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Machine Learning Methods**</span>
<span id="cb1-442"><a href="#cb1-442" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>and many more.</span>
<span id="cb1-443"><a href="#cb1-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-444"><a href="#cb1-444" aria-hidden="true" tabindex="-1"></a>These unified dictionaries provide synonym resolution capabilities to handle variations in terminology commonly encountered across scientific literature.</span>
<span id="cb1-445"><a href="#cb1-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-446"><a href="#cb1-446" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb1-447"><a href="#cb1-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-448"><a href="#cb1-448" aria-hidden="true" tabindex="-1"></a><span class="fu"># References</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Written by Alex Godinez | <a href="https://github.com/agodinezmm2007">GitHub</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>